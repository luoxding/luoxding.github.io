[{"content":"后来纸媒衰落，有人借助积累的资源，出来创业；有人凭借出色能力，跳到大公司。\n他们却开始着急起来，可没有过硬的技能和本领，想有份高收入谈何容易。\n钱的背后，是事儿。我们所赚的每一分钱，都有做事的因果。\n当下的沉溺懈怠，就是在给未来的自己埋雷。\n而眼下获得的成就，也必然是当初长久坚持的回响。\n我想很多朋友，应该看过张艺谋导演的电影《满江红》。\n但对于影片海报中满是狂放之意的“满江红”三字出自谁人之手，却鲜有人知。\n","permalink":"http://localhost:1313/abouta/","summary":"\u003cp\u003e后来纸媒衰落，有人借助积累的资源，出来创业；有人凭借出色能力，跳到大公司。\u003c/p\u003e","title":"格式与元素测试"},{"content":"因为愚蠢，会坚信自己的想法才是对的；因为贪婪，永远想要更多。为了满足私欲，不惜伤害任何人，包括帮助自己的人。\n示例 # Hugo export BLOG_HOME=\u0026#34;$HOME/Blog\u0026#34; export POST_HOME=\u0026#34;$BLOG_HOME/content/posts\u0026#34; alias hs=\u0026#34;cd $BLOG_HOME \u0026amp;\u0026amp; hugo server -D\u0026#34; alias hd=\u0026#34;cd $BLOG_HOME \u0026amp;\u0026amp; sh deploy.sh\u0026#34; alias hb=\u0026#34;cd $BLOG_HOME \u0026amp;\u0026amp; rm -rf public/* \u0026amp;\u0026amp; hugo\u0026#34; alias ht=\u0026#34;cd $BLOG_HOME \u0026amp;\u0026amp; rm -rf themes/PaperMod \u0026amp;\u0026amp; git submodule update --remote --merge\u0026#34; hn() { cd $BLOG_HOME \u0026amp;\u0026amp; hugo new posts/$(date +%Y)/$1/index.md } 我的修改 ### Hugo ================================================================ export BLOG_HOME=\u0026#34;$HOME/Project/Blog\u0026#34; export POST_HOME=\u0026#34;$BLOG_HOME/content/posts\u0026#34; alias hs=\u0026#34;cd $BLOG_HOME \u0026amp;\u0026amp; hugo server -D\u0026#34; alias hd=\u0026#34;cd $BLOG_HOME \u0026amp;\u0026amp; sh deploy.sh\u0026#34; alias hb=\u0026#34;cd $BLOG_HOME \u0026amp;\u0026amp; rm -rf public/* \u0026amp;\u0026amp; hugo\u0026#34; alias ht=\u0026#34;cd $BLOG_HOME \u0026amp;\u0026amp; rm -rf themes/PaperMod \u0026amp;\u0026amp; git submodule update --remote --merge\u0026#34; hn() { cd $BLOG_HOME \u0026amp;\u0026amp; hugo new posts/$(date +%Y-%m-%d)_$1.md } ","permalink":"http://localhost:1313/newdemo/","summary":"\u003cp\u003e因为愚蠢，会坚信自己的想法才是对的；因为贪婪，永远想要更多。为了满足私欲，不惜伤害任何人，包括帮助自己的人。\u003c/p\u003e","title":"创建hugo文章带日期"},{"content":"某周四下午 MQ 堆积，偶发性接口响应慢\n第一次排查 发现下午 CPU 飙高时间，与 MQ 堆积时间点吻合\n同事：”近日新增了下午开始的定时任务，会发出大量 MQ“。\n我们很快达成一致，将锅甩给了定时任务引起了资源占用\n向老板反馈：定时任务时间需要挪到半夜闲时，并按此方案解决\n错误发酵 由于未复现问题和精准定位，并草率给出结论，问题再次浮现\n第二周的周五下午：偶发性接口响应慢，1/4服务器CPU飙高，发现内存溢出异常\n第二次排查 判断可能是由于某些异常代码的执行或调用引起的 查询问题前后时间范围内的 API 网关记录 从调用次数、响应时间上，过滤出接口 A 和接口 B 其中 A 为数据查询，外部调用次数非常频繁，且有少量明显超时 B 为数据导出，响应时长正常可达分钟级 内存快照分析 尝试导出异常服务器上的内存快照，失败，因为16gb 的文件，从跳板机导出受云桌面和网络限制，几乎无法正常导出（必中断） 从公司内部云服务找到线上 JVM 分析工具，尝试使用 Arthas 分析内存快照和GC\n能发现 full GC 次数明显大于其他正常服务器\n但内存快照分析失败（文件体积和线上工具性能制约） 此时发现线上 JVM 分析工具能提供出内存快照下载 开始下载内存快照至云桌面，企图于本地使用 VisualVM 进行分析 VisualVM 加载内存快照预估 1.5 小时，时间也来到晚 8 点，俩人再次达成一致：先回家，到家再看 Jconsole 终于加载完了，可能云桌面性能问题，堆内存分析和类列表加载仍然卡在 loading 无法分析（云桌面内存占用已经 98%） VisualVM 分析失败后，我尝试将内存快照导入至 IDEA Profiler 中 加载成功（给 IDEA 点赞!!!），发现了海量的 C 类变量，明显与正常服务器的类变量不同 经过对 C 类的调用查询，定位到了接口 B、C、D 等，但按时间上看，接口 B 的嫌疑最大 于本地环境调用接口 B，成功引起本地服务 OOM 功能（我太傻了，我一开始就这么做不就好了） 时间 24 点，暂时定论为接口 B 引起，问题延迟至周一解决 第三周的周一早上：于测试环境调用接口 B，成功复现问题：内存快速溢出、CPU 占用高、服务器逐渐不可用\n代码分析、解决 代码逻辑：查询并构建出树状数据，导出为 Excel，最差查询场景单次查询会达到10W+数据量，且有循环子查询场景，即：多个大数据量查询。 问题点： 同事之前对该功能做了查询优化，限制了查询字段，但优化中丢失了某个过滤条件，导致最差查询场景下会进行千万级数据的全表查询 代码对大批量数据的查询处理不太正确，不应一次查询数万的数据 解决方案： 熔断：网关层面禁止了该接口的调用，返回空结果 重启：重启内存溢出的服务器节点，使其恢复正常运行 代码修复 补全丢失的查询逻辑 优化大批量数据查询： 原始方式：find(\u0026hellip;) 优化后：先获取 MongoCursor，参考[1]，调用 MongoCursor 的 foreachRemaing 方法进行迭代处理，参考[2] 漏了什么没做？ 对于要查询返回给用户的数据，应该先对查询条件和查询量做校验 查询条件为空的，即获取全量数据，要与需求业务方讨论是否合理 数据查出前应先查询数据量，对数据量做保险丝校验，超过上限值应直接报错，禁止数据查出和返回，防止服务雪崩。 预想方案：代理模式，拦截 SQL ，预先执行 count 查询和判断 总结 分析问题不能草率，应有理有据。 写代码时，对于可能引起的异常场景要心里有数，应有最基本的压力测试，不能写过且过。 引用： [参考1] MongoCursor\n[参考2] Iterator\n","permalink":"http://localhost:1313/%E4%B8%80%E6%AC%A1%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/","summary":"分析问题不能草率，应有理有据","title":"一次内存溢出问题排查"},{"content":"标题 docker-compose教程（安装，使用, 快速入门）\ncurl -L https://get.daocloud.io/docker/compose/releases/download/1.25.1/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose ","permalink":"http://localhost:1313/linux-note/","summary":"标题 docker-compose教程（安装，使用, 快速入门）\ncurl -L https://get.daocloud.io/docker/compose/releases/download/1.25.1/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose ","title":"Linux Note"},{"content":"Latex 制作表格 前言 提示：这里可以添加本文要记录的大概内容：\nLatex 表格代码汇总，包括三线表[跨页]、简单表[表格基本配置（表名、表宽、注解、字号）]、单元格合并、斜线表头、\n提示：以下是本篇文章正文内容，下面案例可供参考\n一、Latex三线表 1、普通三线表 三线表需要一个专门的宏包==booktabs==。通过该宏包，可以使用以下代码画不同粗细的表线。\n代码 含义 \\toprule 顶部粗线 \\midrule 中间细线 \\bottomrule 底部粗线 示例代码：\n\\documentclass{article} \\usepackage{booktabs} % 导入三线表需要的宏包 \\begin{document} \\begin{tabular}{ccc}% 其中，tabular是表格内容的环境；c表示centering，即文本格式居中；c的个数代表列的个数 \\toprule %[2pt]设置线宽 a \u0026amp; b \u0026amp; c \\\\ %换行 \\midrule %[2pt] 1 \u0026amp; 2 \u0026amp; 3 \\\\ 4 \u0026amp; 5 \u0026amp; 6 \\\\ 7 \u0026amp; 8 \u0026amp; 9 \\\\ \\bottomrule %[2pt] \\end{tabular} \\end{document} 代码结果图片：\n2、跨页三线表 跨页表格需要导入宏包 ==longtable==，并将原来的表格内容环境==tabular==改成==longtable==即可。\n示例代码：\n\\documentclass{article} \\usepackage{booktabs} % 导入三线表需要的宏包 \\usepackage{longtable}% 导入跨页表格所需宏包 \\begin{document} \\begin{longtable}{ccc}% 其中，tabular是表格内容的环境；c表示centering，即文本格式居中；c的个数代表列的个数 \\toprule %[2pt]设置线宽 a \u0026amp; b \u0026amp; c \\\\ %换行 \\midrule %[2pt] 1 \u0026amp; 2 \u0026amp; 3 \\\\ 4 \u0026amp; 5 \u0026amp; 6 \\\\ 7 \u0026amp; 8 \u0026amp; 9 \\\\ \\bottomrule %[2pt] \\end{longtable} \\end{document} 代码结果图片：\n二、简单表 1、基本需求表 表格，简而言之就是被 横竖表线 框起来文本。\n1.横线：\n代码 含义 \\hline 表格所有列的一整条表线 \\cline{a-b} 指定列数的表线，a-b表示从第a列到第b列 2.竖线：| |\n3.文本位置：\n参数 含义 c centering，表示文本居中 l left，表示文本靠左 r rigth，表示文本靠右 参考代码：\n\\begin{document} \\begin{tabular}{|c|c|c|c|r|l|} \\hline % 其中，|c|表示文本居中，文本两边有竖直表线。 aaaaa \u0026amp; bbbbb \u0026amp; ccccc \u0026amp; ddddd \u0026amp; eeeee \u0026amp; fffff \\\\ \\hline 1 \u0026amp; 2 \u0026amp; 3 \u0026amp; 4 \u0026amp; 5 \u0026amp; 6 \\\\ \\hline 7 \u0026amp;\t8 \u0026amp;\t9 \u0026amp;\t10 \u0026amp; 11 \u0026amp; 12\\\\ \\hline 13 \u0026amp; 14 \u0026amp; 15 \u0026amp; 16 \u0026amp;\t17 \u0026amp; 18\\\\ \\hline \\end{tabular} \\end{document} 代码结果图片：\n2、表格整体相关设置【表名及位置、表宽、注解、字号】 很多时候，我们都是对表格整体进行相关设置，来达到自己的相关需求。而对表格整体的相关设置其实与表格内容并无太大关系。\n因此我们需要在表格内容环境【如上文中的 \\begin{tabular}、\\begin{longtable} 】外面进行相关环境设置。\n\\begin{table}%表格环境 ...表格整体相关设置 \\begin{tabular}% 表格内容环境 \\end{tabular} ...表格整体相关设置 \\end{table} 1. 表格标题及位置 1.标题\n导入宏包 ==caption==，使用代码：==\\caption{表格标题}==（位置上下均可）\n2.位置\n==\\begin{table}[!ht]==，中的参数 ==!ht== 就是对表格位置的相关设置。\n==[!ht]== 这个参数组合是我比较喜欢用的，含义：尽量放在代码当前位置，实在放不下，将放在下一页的顶部。\n其他参数及含义如下：\n参数 含义 h （here）代码当前位置 t （top）页面顶部 b (bottom) 页面底部 p 单独一个页面，只含浮动对象 ！ 忽略系统排版美学因素，尽可能按照你的代码参数放置表格位置 H 需导入宏包 ==float== ,放在当前代码位置，放不下则不显示（错误） 位置参数参考\n参考代码：\n\\begin{table}[!ht] % [!ht]表格在文本中放置的位置参数（努力放在当前位置，实在放不下，将放在下一页的顶部） \\centering % 表格整体居中 \\caption{表格标题} \\begin{tabular}{|c|c|c|c|r|l|} \\hline % 其中，|c|表示文本居中，文本两边有竖直表线。 aaaaa \u0026amp; bbbbb \u0026amp; ccccc \u0026amp; ddddd \u0026amp; eeeee \u0026amp; fffff \\\\ \\hline 1 \u0026amp; 2 \u0026amp; 3 \u0026amp; 4 \u0026amp; 5 \u0026amp; 6 \\\\ \\hline 7 \u0026amp;\t8 \u0026amp;\t9 \u0026amp;\t10 \u0026amp; 11 \u0026amp; 12\\\\ \\hline 13 \u0026amp; 14 \u0026amp; 15 \u0026amp; 16 \u0026amp;\t17 \u0026amp; 18\\\\ \\hline \\end{tabular} \\end{table} 代码结果图片：\n2. 表宽设置 由于latex的表格长宽都是通过表格中文本的最大长度来设定的，这就可能造成表格过窄或过宽导致的不美观现象。\n因此，如果你对表格的美观程度要求较高的话，就还需要设定一些参数。\n1.自定义表格整体大小\n首先需要导入==graphics、graphicx、pdfpages== 这三个宏包中的任意一个，然后在表格内部环境外面进行相关设置。\n==resizebox{表宽}{表长}{…表格内部环境…}==\n其中，表宽和表长可以自己定义多少厘米，也可以采用页面的相关长度来进行设置。\n以下是相关参数及含义：\n参数 含义 \\linewidth 当前环境宽度，即上下文宽度 \\textwidth 文本宽度 ！ （高度或宽度）随着另一个参数的改变而改变 宽度参数参考\n存在的缺陷：改变了表格的大小，同时也会自动改变表格中文本字体的大小，如果你对表格中的字体还有要求的话，那么这个代码并不适用。\n参考代码：\n\\usepackage{graphics} \\begin{document} \\begin{table}[!ht] \\resizebox{\\textwidth}{!}{ % 表格环境外部设置（头） \\begin{tabular}{|c|c|c|c|r|l|} \\hline % 其中，|c|表示文本居中，文本两边有竖直表线。 aaaaa \u0026amp; bbbbb \u0026amp; ccccc \u0026amp; ddddd \u0026amp; eeeee \u0026amp; fffff \\\\ \\hline 1 \u0026amp; 2 \u0026amp; 3 \u0026amp; 4 \u0026amp; 5 \u0026amp; 6 \\\\ \\hline 7 \u0026amp;\t8 \u0026amp;\t9 \u0026amp;\t10 \u0026amp; 11 \u0026amp; 12\\\\ \\hline 13 \u0026amp; 14 \u0026amp; 15 \u0026amp; 16 \u0026amp;\t17 \u0026amp; 18\\\\ \\hline \\end{tabular} }% 外部环境设置（尾） \\end{table} \\end{document} 代码结果图片：\n2. 设置每列文本宽度\n① ==\\setlength{\\tabcolsep}{宽度}{…表格内部环境…}==，设置表格中每列的宽度（每个单元格都是一样的）。\n② 导入宏包==array==，使用 ==\\begin{tabular}{宽度设置}== 进行设置\n宽度设置相关参数：\n参数 含义 p{宽度} 指定单元格宽度，==汉字内容==超出宽度自动换行，文本在单元格中的位置为垂直靠上 m{宽度} 指定单元格宽度，==汉字内容==超出宽度自动换行，文本在单元格中的位置为垂直居中 b{宽度} 指定单元格宽度，==汉字内容==超出宽度自动换行，文本在单元格中的位置为垂直靠下 \u0026lt;{\\raggedright} 单元格内容左对齐 \u0026lt;{\\raggedleft} 单元格内容右对齐 \u0026lt;{\\centering} 单元格内容居中 参考代码：\n\\begin{tabular}{|p{6cm}\u0026lt;{\\raggedleft}|p{4cm}\u0026lt;{\\raggedright}|p{4cm}\u0026lt;{\\centering}|} \\hline 汉字文本文本文本文本\u0026amp;汉字文本文本文本文本汉字文本文本文本文本\u0026amp;汉字文本文本文本文本汉字文本文本文本文本汉字文本文本文本文本\\\\ \\hline 汉字文本\u0026amp;汉字文本\u0026amp;汉字文本\\\\ \\hline aaaaaaaaa\u0026amp;aaaaaaaaa\u0026amp;aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\\\\ \\hline 111111111\u0026amp;111111111\u0026amp;111111111111111111111111111111111111\\\\ \\hline \\end{tabular} 代码结果图片：\n文本对齐参数参考\n3.更多方法\n当然，如果你实在不想管这些东西，你还可以利用空格来增加文本的宽度，快速的得到你想要的表格。\n空格的相关设置参数如下：\n参数 含义 a\\ b ab之间1个m的宽度 a\\quad b ab之间2个m的宽度 空格参数参考\n3. 表格注解 导入宏包 ==threeparttable==，使用 ==\\begin{threeparttable}== 进行设置。\n参考代码：\n\\centering \\begin{threeparttable} \\begin{tabular}{|c|c|c|c|c|c|} \\hline 班级层次\u0026amp;平均值\t\u0026amp;个案数\t\u0026amp;标准偏差\t\u0026amp;最小值\u0026amp;最大值\\\\ \\hline 1\u0026amp;\t53.74\u0026amp;\t77\t\u0026amp;29.819\u0026amp;\t4\t\u0026amp;96\\\\ \\hline 2\t\u0026amp;57.60\t\u0026amp;119\u0026amp;\t28.971\u0026amp;\t4\t\u0026amp;100\\\\ \\hline 3\t\u0026amp;58.94\u0026amp;\t119\u0026amp;\t29.930\t\u0026amp;0\u0026amp;\t100\\\\ \\hline 总计\t\u0026amp;57.16\t\u0026amp;315\t\u0026amp;29.520\u0026amp;\t0\u0026amp;\t100\\\\ \\hline \\end{tabular} 注： 1代表学习成绩低的同学；2代表学习层次居中的同学；3代表学习层次较好的同学。 \\end{threeparttable} 代码结果图片：\n4. 字号设置 由前文对表格整体的设置可知，当对表格整体进行设置的时候，只需在表格内容环境的外面进行相关设置，就可以改变表格的整体。\n同样的，字号也是一样，字号设置的位置决定了你的作用域在哪里。\n下面给出字体设置的相关参数：\n参数 含义 \\small 小五 \\large 小四 字体字号参数参考\n三、复杂表 1、合并单元格 导入宏包 ==multirow==\n对行合并：使用 ==\\multirow{合并行数}{}{文本内容}==\n对列合并：使用 ==\\multicolumn{合并列数}{c|}{文本内容}==\n对行列进行合并：使用 ==\\multicolumn{合并列数}{|c|}{\\multirow{合并行数}{}{内容}}==\n参考代码：\n\\begin{table}[!ht] \\center \\begin{tabular}{|c|c|c|c|}\\hline \\multicolumn{1}{|c|}{\\multirow{2}{*}{aaaa}} \u0026amp; \\multicolumn{3}{c|}{bbbb}\\\\ \\cline{2-4} \u0026amp; cccc \u0026amp; dddd \u0026amp; eeee \\\\ \\hline \\multirow{2}{*}{aaaa}\u0026amp; 50 \u0026amp; 86 \u0026amp; 122 \\\\ \\cline{2-4} \\multirow{2}{*}{ }\u0026amp; 5 \u0026amp; 78 \u0026amp; 107 \\\\ \\hline 3\u0026amp; 25 \u0026amp; 48 \u0026amp; 101 \\\\ \\hline 4\u0026amp; 28 \u0026amp; 60 \u0026amp; 106 \\\\ \\hline \\end{tabular} \\end{table} 代码结果图片：\n2、斜线表头 导入宏包==diagbox==\n利用 ==\\diagbox{A}{B}{C}== 来写某个单元格的分块内容\n代码参考：\n\\centering \\begin{threeparttable} \\begin{tabular}{|c|c|c|c|c|c|} \\hline \\diagbox{班级层次}{班级层次}\u0026amp;平均值\t\u0026amp;个案数\t\u0026amp;标准偏差\t\u0026amp;最小值\u0026amp;最大值\\\\ \\hline 1\u0026amp;\t53.74\u0026amp;\t77\t\u0026amp;29.819\u0026amp;\t4\t\u0026amp;96\\\\ \\hline 2\t\u0026amp;57.60\t\u0026amp;119\u0026amp;\t28.971\u0026amp;\t4\t\u0026amp;100\\\\ \\hline 3\t\u0026amp;58.94\u0026amp;\t119\u0026amp;\t29.930\t\u0026amp;0\u0026amp;\t100\\\\ \\hline 总计\t\u0026amp;57.16\t\u0026amp;315\t\u0026amp;29.520\u0026amp;\t0\u0026amp;\t100\\\\ \\hline \\end{tabular} 注： 1代表学习成绩低的同学；2代表学习层次居中的同学；3代表学习层次较好的同学。 \\end{threeparttable} 代码结果图片：\n斜线表头参考\n五、常用表格模板代码 1.代码1：\n\\begin{table*}[!ht] %\\usepackage{multirow} \\center \\caption{不同层次学生显著性分析} \\begin{threeparttable} \\resizebox{\\linewidth}{!}{ \\begin{tabular}{|c|c|c|c|c|c|c|c|} \\hline \\multirow{2}{*}{} \u0026amp;\\multirow{2}{*}{(I) 班级层次} \u0026amp;\\multirow{2}{*}{(J) 班级层次} \u0026amp;\\multirow{2}{*}{平均值差值 (I-J)} \u0026amp;\\multirow{2}{*}{标准 错误} \u0026amp;\\multirow{2}{*}{显著性} \u0026amp;\\multicolumn{2}{c|}{95\\% 置信区间}\\\\ \\cline{7-8} \\multirow{2}{*}{}\u0026amp;\\multirow{2}{*}{} \u0026amp;\\multirow{2}{*}{} \u0026amp;\\multirow{2}{*}{} \u0026amp;\\multirow{2}{*}{} \u0026amp;\\multirow{2}{*}{} \u0026amp;上限\u0026amp;下限 \\\\ \\hline \\multirow{6}{*}{塔姆黑尼}\u0026amp;\\multirow{2}{*}{1} \u0026amp;2\u0026amp;\t-3.856\t\u0026amp;4.313\t\u0026amp;.753\u0026amp;\t-14.26\u0026amp;\t6.55 \\\\ \\cline{3-8} \\multirow{6}{*}{}\u0026amp;\\multirow{2}{*}{} \u0026amp; 3\t\u0026amp;-5.201\u0026amp;4.368\u0026amp;\t.553\u0026amp;\t-15.74\u0026amp;\t5.34 \\\\ \\cline{2-8} \\multirow{6}{*}{}\u0026amp;\\multirow{2}{*}{2} \u0026amp;1\u0026amp;\t3.856\u0026amp;\t4.313\u0026amp;\t.753\u0026amp;\t-6.55\u0026amp;\t14.26 \\\\ \\cline{3-8} \\multirow{6}{*}{}\u0026amp;\\multirow{2}{*}{} \u0026amp; 3\u0026amp;\t-1.345\t\u0026amp;3.819\u0026amp;\t.979\t\u0026amp;-10.53\u0026amp;\t7.84\\\\ \\cline{2-8} \\multirow{6}{*}{}\u0026amp;\\multirow{2}{*}{3} \u0026amp;1\u0026amp;\t5.201\u0026amp;\t4.368\u0026amp;\t.553\t\u0026amp;-5.34\u0026amp;\t15.74 \\\\ \\cline{3-8} \\multirow{6}{*}{}\u0026amp;\\multirow{2}{*}{} \u0026amp; 2\t\u0026amp;1.345\u0026amp;\t3.819\u0026amp;\t.979\u0026amp;\t-7.84\t\u0026amp;10.53 \\\\ \\hline \\multirow{2}{*}{邓尼特 t（双侧）} \u0026amp; 1\u0026amp;\t3\t\u0026amp;-5.201\u0026amp;4.321\t\u0026amp;.384\u0026amp;\t-14.83\t\u0026amp;4.43 \\\\ \\cline{2-8} \\multirow{2}{*}{} \u0026amp; 2\u0026amp;\t3\u0026amp;\t-1.345\t\u0026amp;3.830\t\u0026amp;.917\t\u0026amp;-9.88\t\u0026amp;7.19\\\\ \\hline \\end{tabular} }\t\\begin{tablenotes} \\item[1] 1代表学习成绩低的同学；2代表学习层次居中的同学；3代表学习层次较好的同学。 \\end{tablenotes} \\end{threeparttable} \\end{table*} 代码1结果图：\n总结 ","permalink":"http://localhost:1313/latex-note/","summary":"Latex 制作表格 前言 提示：这里可以添加本文要记录的大概内容：\nLatex 表格代码汇总，包括三线表[跨页]、简单表[表格基本配置（表名、表宽、注解、字号）]、单元格合并、斜线表头、\n提示：以下是本篇文章正文内容，下面案例可供参考\n一、Latex三线表 1、普通三线表 三线表需要一个专门的宏包==booktabs==。通过该宏包，可以使用以下代码画不同粗细的表线。\n代码 含义 \\toprule 顶部粗线 \\midrule 中间细线 \\bottomrule 底部粗线 示例代码：\n\\documentclass{article} \\usepackage{booktabs} % 导入三线表需要的宏包 \\begin{document} \\begin{tabular}{ccc}% 其中，tabular是表格内容的环境；c表示centering，即文本格式居中；c的个数代表列的个数 \\toprule %[2pt]设置线宽 a \u0026amp; b \u0026amp; c \\\\ %换行 \\midrule %[2pt] 1 \u0026amp; 2 \u0026amp; 3 \\\\ 4 \u0026amp; 5 \u0026amp; 6 \\\\ 7 \u0026amp; 8 \u0026amp; 9 \\\\ \\bottomrule %[2pt] \\end{tabular} \\end{document} 代码结果图片：\n2、跨页三线表 跨页表格需要导入宏包 ==longtable==，并将原来的表格内容环境==tabular==改成==longtable==即可。\n示例代码：\n\\documentclass{article} \\usepackage{booktabs} % 导入三线表需要的宏包 \\usepackage{longtable}% 导入跨页表格所需宏包 \\begin{document} \\begin{longtable}{ccc}% 其中，tabular是表格内容的环境；c表示centering，即文本格式居中；c的个数代表列的个数 \\toprule %[2pt]设置线宽 a \u0026amp; b \u0026amp; c \\\\ %换行 \\midrule %[2pt] 1 \u0026amp; 2 \u0026amp; 3 \\\\ 4 \u0026amp; 5 \u0026amp; 6 \\\\ 7 \u0026amp; 8 \u0026amp; 9 \\\\ \\bottomrule %[2pt] \\end{longtable} \\end{document} 代码结果图片：","title":"Latex Note"},{"content":"总所周知，OpenAI 对于访问 IP 的要求较为严格，因此我们最好使用较为固定的美国 IP 进行访问。如果我们所使用的分流规则中没有相应的规则的话，我们每次访问 ChatGPT 时都需要手动切换节点，非常的麻烦。那么有没有什么简单的方法来添加 Clash 的分流规则呢？当然有，那就是 Clash for Windows 的 Parsers 功能。\n打开 CFW 的 Settings - Profiles，可以找到 Parsers 选项。我们需要添加一个 OpenAI 的分流代理组，再为相关域名添加规则。如下所示，将你的配置文件的 URL 填入 url 项，在 OpenAI 的 proxies 中填入美国节点。\nparsers: # array - url: YOUR_URL yaml: append-proxy-groups: - name: z OpenAI type: select proxies: - 美国-01 - 美国-02 - 美国-03 prepend-rules: - DOMAIN-SUFFIX,openai.com,🚀 OpenAI - DOMAIN-SUFFIX,oaistatic.com,🚀 OpenAI - DOMAIN-SUFFIX,oaiusercontent.com,🚀 OpenAI - DOMAIN-SUFFIX,poe.com,🚀 OpenAI 当然，Parsers 也可以方便地添加其他代理规则，例如我们还可以添加一条规则，使它直连\n- DOMAIN-SUFFIX,msftconnecttest.com,🍂 Domestic Parsers 的相关参数说明如下表\n键 操作 append-rules 数组合并至原配置 rules 数组后 prepend-rules 数组合并至原配置 rules 数组前 append-proxies 数组合并至原配置 proxies 数组后 prepend-proxies 数组合并至原配置 proxies 数组前 append-proxy-groups 数组合并至原配置 proxy-groups 数组后 prepend-proxy-groups 数组合并至原配置 proxy-groups 数组前 mix-proxy-providers 对象合并至原配置 proxy-providers 中 mix-rule-providers 对象合并至原配置 rule-providers 中 mix-object 对象合并至原配置最外层中 commands 在上面操作完成后执行简单命令操作配置文件 ","permalink":"http://localhost:1313/clash-openai/","summary":"\u003cp\u003e总所周知，OpenAI 对于访问 IP 的要求较为严格，因此我们最好使用较为固定的美国 IP 进行访问。如果我们所使用的分流规则中没有相应的规则的话，我们每次访问 ChatGPT 时都需要手动切换节点，非常的麻烦。那么有没有什么简单的方法来添加 Clash 的分流规则呢？当然有，那就是 Clash for Windows 的 Parsers 功能。\u003c/p\u003e","title":"Clash for Windows OpenAI 分流"},{"content":"llm-term Chat with LLM models directly from the command line.\nScreen Recording Your browser does not support the video tag. Installation pipx install llm-term Usage Then, you can chat with the model directly from the command line:\nllm-term llm-term works with multiple LLM providers, but by default it uses OpenAI. Most providers require extra packages to be installed, so make sure you read the Providers section below. To use a different provider, you can set the --provider / -p flag:\nllm-term --provider anthropic If needed, make sure you have your LLM\u0026rsquo;s API key set as an environment variable (this can also set via the --api-key / -k flag in the CLI). If your LLM uses a particular environment variable for its API key, such as OPENAI_API_KEY, that will be detected automatically.\nexport LLM_API_KEY=\u0026#34;xxxxxxxxxxxxxx\u0026#34; Optionally, you can set a custom model. llm-term defaults to gpt-3.5-turbo (this can also set via the --model / -m flag in the CLI):\nexport LLM_MODEL=\u0026#34;gpt-4\u0026#34; Want to start the conversion directly from the command line? No problem, just pass your prompt to llm-term:\nllm-term show me python code to detect a palindrome You can also set a custom system prompt. llm-term defaults to a reasonable prompt for chatting with the model, but you can set your own prompt (this can also set via the --system / -s flag in the CLI):\nexport LLM_SYSTEM_MESSAGE=\u0026#34;You are a helpful assistant who talks like a pirate.\u0026#34; Providers OpenAI By default, llm-term uses OpenAI as your LLM provider. The default model is gpt-3.5-turbo and you can also use the OPENAI_API_KEY environment variable to set your API key.\nAnthropic Anthropic is a new LLM provider that is currently in private beta. You can request access to the beta here. The default model is claude, and you can use the ANTHROPIC_API_KEY environment variable. To use anthropic as your provider you must install the anthropic extra.\npipx install \u0026#34;llm-term[anthropic]\u0026#34; llm-term --provider anthropic GPT4All GPT4All is a an open source LLM provider. These models run locally on your machine, so you don\u0026rsquo;t need to worry about API keys or rate limits. The default model is mistral-7b-openorca.Q4_0.gguf, and you can see what models are available on the GPT4All Website. Models are downloaded automatically when you first use them. To use GPT4All as your provider you must install the gpt4all extra.\npipx install \u0026#34;llm-term[gpt4all]\u0026#34; llm-term --provider gpt4all --model mistral-7b-openorca.Q4_0.gguf ","permalink":"http://localhost:1313/manual/2023-09-26-llm-term/","summary":"llm-term Chat with LLM models directly from the command line.\nScreen Recording Your browser does not support the video tag. Installation pipx install llm-term Usage Then, you can chat with the model directly from the command line:\nllm-term llm-term works with multiple LLM providers, but by default it uses OpenAI. Most providers require extra packages to be installed, so make sure you read the Providers section below. To use a different provider, you can set the --provider / -p flag:","title":"Chat with LLMs from the command line"},{"content":"llm-term Chat with LLM models directly from the command line.\nScreen Recording Your browser does not support the video tag. Installation pipx install llm-term Usage Then, you can chat with the model directly from the command line:\nllm-term llm-term works with multiple LLM providers, but by default it uses OpenAI. Most providers require extra packages to be installed, so make sure you read the Providers section below. To use a different provider, you can set the --provider / -p flag:\nllm-term --provider anthropic If needed, make sure you have your LLM\u0026rsquo;s API key set as an environment variable (this can also set via the --api-key / -k flag in the CLI). If your LLM uses a particular environment variable for its API key, such as OPENAI_API_KEY, that will be detected automatically.\nexport LLM_API_KEY=\u0026#34;xxxxxxxxxxxxxx\u0026#34; Optionally, you can set a custom model. llm-term defaults to gpt-3.5-turbo (this can also set via the --model / -m flag in the CLI):\nexport LLM_MODEL=\u0026#34;gpt-4\u0026#34; Want to start the conversion directly from the command line? No problem, just pass your prompt to llm-term:\nllm-term show me python code to detect a palindrome You can also set a custom system prompt. llm-term defaults to a reasonable prompt for chatting with the model, but you can set your own prompt (this can also set via the --system / -s flag in the CLI):\nexport LLM_SYSTEM_MESSAGE=\u0026#34;You are a helpful assistant who talks like a pirate.\u0026#34; Providers OpenAI By default, llm-term uses OpenAI as your LLM provider. The default model is gpt-3.5-turbo and you can also use the OPENAI_API_KEY environment variable to set your API key.\nAnthropic Anthropic is a new LLM provider that is currently in private beta. You can request access to the beta here. The default model is claude, and you can use the ANTHROPIC_API_KEY environment variable. To use anthropic as your provider you must install the anthropic extra.\npipx install \u0026#34;llm-term[anthropic]\u0026#34; llm-term --provider anthropic GPT4All GPT4All is a an open source LLM provider. These models run locally on your machine, so you don\u0026rsquo;t need to worry about API keys or rate limits. The default model is mistral-7b-openorca.Q4_0.gguf, and you can see what models are available on the GPT4All Website. Models are downloaded automatically when you first use them. To use GPT4All as your provider you must install the gpt4all extra.\npipx install \u0026#34;llm-term[gpt4all]\u0026#34; llm-term --provider gpt4all --model mistral-7b-openorca.Q4_0.gguf ","permalink":"http://localhost:1313/manual/linux/2023-09-26-llm-term/","summary":"llm-term Chat with LLM models directly from the command line.\nScreen Recording Your browser does not support the video tag. Installation pipx install llm-term Usage Then, you can chat with the model directly from the command line:\nllm-term llm-term works with multiple LLM providers, but by default it uses OpenAI. Most providers require extra packages to be installed, so make sure you read the Providers section below. To use a different provider, you can set the --provider / -p flag:","title":"Chat with LLMs from the command line"},{"content":" zoo The zoo project 🦁🐼🐨, an asynchronous zoo API powered by FastAPI, SQLAlchemy 2.0, Pydantic v2, and Alembic. zoo is a simple yet robust API example that allows you to manage a zoo. It utilizes modern tools and practices, including a production-ready server (Uvicorn), modern SQL ORM (SQLAlchemy 2.0), data validation (Pydantic v2), and database migrations (Alembic). This project serves as an excellent starting point for building your own API, outlining the basic structure of an API project and providing examples of implementing common features.\nAsynchronous ASGI Framework (FastAPI) Production Ready Server (Uvicorn) Modern SQL ORM (SQLAlchemy 2.0) Data Validation (Pydantic v2) Authentication (fastapi-users) Database Migrations (Alembic) Docker Images (Docker) Documentation (mkdocs-material) Testing (pytest) CI/CD (GitHub Actions) Python Environment Management (hatch) Release Automation (semantic-release) Serverless Deployment (Mangum + AWS Lambda) Worker Queues (Celery) API Caching (redis) What else? ","permalink":"http://localhost:1313/manual/linux/2023-08-23-zoo/","summary":"zoo The zoo project 🦁🐼🐨, an asynchronous zoo API powered by FastAPI, SQLAlchemy 2.0, Pydantic v2, and Alembic. zoo is a simple yet robust API example that allows you to manage a zoo. It utilizes modern tools and practices, including a production-ready server (Uvicorn), modern SQL ORM (SQLAlchemy 2.0), data validation (Pydantic v2), and database migrations (Alembic). This project serves as an excellent starting point for building your own API, outlining the basic structure of an API project and providing examples of implementing common features.","title":"API starterpack with zoo"},{"content":"本文介绍了 PyTorch 中 Tensor 的一些常用操作。\n1. 初始化 操作 效果 ones(3, 4) 全 1 zeros(3, 4) 全 0 eye(3) 对角阵 arange(0, 5, 1) 从 0 到 4 步长为 1 rand(3, 4) 0 到 1 随机数 randn(3, 4) 正态分布随机数 2. 基本属性 操作 效果 shape 形状 numel() 元素个数 max() 最大值 device 所在的位置 abs() 绝对值 grad 梯度 reshape() 改变形状 在 reshape 时，我们可以通过 -1 来自动计算维度。如 x 为 size([12]) 的 tensor，x.reshape([3, -1])，可以得到 size([3, 4])。而在使用下标访问 tensor 元素时，-1 表示最后一个元素。如上文的 x[-1][-1] 就表示 x[2][3]。\n另外，函数名后加下划线意为原地操作，如 abs_() 为 abs() 的原地版本\n3. 拼接（cat/stack） cat 在现有维度上进行拼接，stack 在新的维度上进行拼接。\na = torch.rand(3, 4) b = torch.rand(3, 4) c = torch.cat((a, b), dim=0) d = torch.stack((a, b), dim=0) print(c.shape) # torch.Size([6, 4]) print(d.shape) # torch.Size([2, 3, 4]) 4. 广播机制 广播机制即对两个形状不同的矩阵来进行按元素操作，如 a 为 size([3, 1])，b 为 size([1, 2])，a + b 会将两个矩阵广播为一个 size([3, 2]) 的矩阵，即复制 a 的行，而复制 b 的列，来进行按元素运算。\na = torch.arange(3).reshape((3, 1)) b = torch.arange(2).reshape((1, 2)) print(a + b) # tensor([[0, 1], [1, 2], [2, 3]]) 5. 基本计算 求和 包括按所有轴求和，按指定轴求和，以及保持维度求和。\nA = torch.tensor([[1, 2], [3, 4]]) print(A.sum()) # tensor(10) print(A.sum(axis=0)) # tensor([4, 6]) print(A.sum(axis=0, keepdim=True)) # tensor([[4, 6]]) 按元素运算 对任意相同形状的 tensor，我们都可以使用常见的运算符（+，-，*，/和**，其中 ** 为求幂运算）来进行按元素运算。 除此之外，按元素还可以使用 exp() 自然指数这样的一元运算符。\nx = torch.tensor([1.0, 2, 4, 8]) y = torch.tensor([2, 2, 2, 2]) x + y, x - y, x * y, x / y, x ** y, x.exp() 上述结果分别为\ntensor([ 3., 4., 6., 10.]), tensor([-1., 0., 2., 6.]), tensor([ 2., 4., 8., 16.]), tensor([0.5000, 1.0000, 2.0000, 4.0000]), tensor([ 1., 4., 16., 64.]) tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03]) 乘法 包括按元素乘法，向量的数量积，向量和矩阵的乘法以及矩阵和矩阵的乘法。\n向量之间的乘法\nx = torch.tensor([1, 2]) y = torch.tensor([3, 4]) print(x * y) # tensor([3, 8]) print(x.dot(y)) # tensor(11) 向量和矩阵的乘法，注意这里的按元素乘法使用了广播机制。\nA = torch.tensor([[1, 2], [3, 4]]) x = torch.tensor([1, 2]) print(A * x) # tensor([[1, 4], [3, 8]]) print(A.mv(x)) # tensor([ 5, 11]) 矩阵之间的乘法\nA = torch.tensor([[1, 2], [3, 4]]) B = torch.tensor([[1, -1], [1, -1]]) print(A * B) # tensor([[ 1, -2], [ 3, -4]]) print(A.mm(B)) print(A @ B) # 上面两句均表示矩阵乘法 # tensor([[ 3, -3], [ 7, -7]]) 6. 自动求导 $$ y = e^{x_1} + e^{x_2} + e^{x_3}$$ $$ y\u0026rsquo;_{x_1} = e^{x_1}$$\nx = torch.arange(4.0, requires_grad=True) print(x) # tensor([0., 1., 2., 3.], requires_grad=True) y = x.exp() print(y) # tensor([ 1.0000, 2.7183, 7.3891, 20.0855], grad_fn=\u0026lt;ExpBackward0\u0026gt;) y.sum().backward() print(x.grad) # tensor([ 1.0000, 2.7183, 7.3891, 20.0855]) $$ y = x_1^2 + x_2^2 + x_3^3 $$ $$ y\u0026rsquo;_{x_1} = 2x_1 $$\nx = torch.arange(4.0, requires_grad=True) print(x) # tensor([0., 1., 2., 3.], requires_grad=True) y = x * x print(y) # tensor([0., 1., 4., 9.], grad_fn=\u0026lt;MulBackward0\u0026gt;) y.sum().backward() print(x.grad) # tensor([0., 2., 4., 6.]) 注意，只有标量的输出才能求梯度，因此我们在对 y 反向传播求梯度之前要先求和。\n","permalink":"http://localhost:1313/pytorch-tensor/","summary":"\u003cp\u003e本文介绍了 PyTorch 中 Tensor 的一些常用操作。\u003c/p\u003e","title":"Pytorch Tensor 基本操作"},{"content":"众所周知，Intel 自 12 代处理器就开始使用大小核架构，把核心分为 P-Core 和 E-Core，即我们所说的大核和小核。Microsoft 声称在 Windows 11 系统上对大小核架构进行了优化。不过，在有些场景下大小核的调度仍不尽如人意，比如本文所探讨的 VMware 虚拟机场景。\n实验环境 本机使用 i9-13900h 处理器，6P + 8E 核，20 线程，操作系统 Windows 11 22H2。创建一台 Ubuntu 22.04 虚拟机，分配 12 个 CPU 核心，编译 boost 项目来测试 CPU 性能。\n下载源码压缩包 boost_1_82_0.tar.gz，然后解压\ntar zxvf boost_1_82_0.tar.gz 进入目录，运行 bootstrap.sh 脚本并设置相关参数\ncd boost_1_82_0/ ./bootstrap.sh --with-libraries=all --with-toolset=gcc 之后编译 boost\n./b2 toolset=gcc 此时，打开宿主机的任务管理器我们可以发现，虚拟机的编译进程竟然全部跑在小核心上，6 个大核纹丝不动，可谓“一核有难，八核围观”。当然，这样编译的性能肯定也上不去了。那么，有什么办法可以解决这一问题呢？\n修改虚拟机 vmx 配置文件 其中的一个办法是修改虚拟机的 vmx 配置文件，打开虚拟机目录下的 .vmx 文件（或全局配置文件：C:\\ProgramData\\VMware\\VMware Workstation\\config.ini），添加如下内容\nprocessor0.use = \u0026#34;TRUE\u0026#34; processor1.use = \u0026#34;TRUE\u0026#34; processor2.use = \u0026#34;TRUE\u0026#34; processor3.use = \u0026#34;TRUE\u0026#34; processor4.use = \u0026#34;TRUE\u0026#34; processor5.use = \u0026#34;TRUE\u0026#34; processor6.use = \u0026#34;TRUE\u0026#34; processor7.use = \u0026#34;TRUE\u0026#34; processor8.use = \u0026#34;TRUE\u0026#34; processor9.use = \u0026#34;TRUE\u0026#34; processor10.use = \u0026#34;TRUE\u0026#34; processor11.use = \u0026#34;TRUE\u0026#34; processor12.use = \u0026#34;FALSE\u0026#34; processor13.use = \u0026#34;FALSE\u0026#34; processor14.use = \u0026#34;FALSE\u0026#34; processor15.use = \u0026#34;FALSE\u0026#34; processor16.use = \u0026#34;FALSE\u0026#34; processor17.use = \u0026#34;FALSE\u0026#34; processor18.use = \u0026#34;FALSE\u0026#34; processor19.use = \u0026#34;FALSE\u0026#34; 注意，处理器的序号需要根据实际情况来调整，如本机 6P + 8E，前 12 个线程设为 TRUE，后面 8 个设为 FALSE，这样就把线程都分配到了 6 个大核上。\n经实际测试，这样确实可以把任务分配到大核心上运行，不过性能好像一般，并不能跑满大核，CPU 的频率一直上不去，只运行在 2.x GHz。\n使用管理员权限运行 VMware 另一个办法是使用管理员权限来运行 VMware Workstation。\n打开 VMware 的安装目录，选择 vmware.exe，右键 - 属性 - 兼容性 - 以管理员身份运行此程序，并重新运行虚拟机。\n同样运行测试，发现可以正常使用大核，并且 CPU 的频率也能跑到 4.x GHz。此外，继续尝试将虚拟机的 CPU 数量设置为 20，运行测试，发现可以完全跑满宿主机 CPU，任务管理器 CPU 占用率达到 100%。\n总结，想要让 VMware 虚拟机正常调度大小核，最简单的方案就是使用管理员身份来运行虚拟机程序。\n","permalink":"http://localhost:1313/vmware-p-core/","summary":"\u003cp\u003e众所周知，Intel 自 12 代处理器就开始使用大小核架构，把核心分为 P-Core 和 E-Core，即我们所说的大核和小核。Microsoft 声称在 Windows 11 系统上对大小核架构进行了优化。不过，在有些场景下大小核的调度仍不尽如人意，比如本文所探讨的 VMware 虚拟机场景。\u003c/p\u003e","title":"VMware 虚拟机大小核调度问题"},{"content":"使用 vite 新建了一个 react 的项目，通过 vscode 打开，发现 .eslintrc.cjs 文件报错：\u0026quot;\u0026lsquo;module\u0026rsquo; is not defined\u0026quot;。经过查阅资料，发现原来是 vscode 的问题。ESLint 本来应该忽略以 . 开头的文件，但在 vscode 中没有生效。解决方案就是在 .eslintrc.cjs 文件中添加 node 环境。就像这样：\nmodule.exports = { env: { browser: true, es2020: true, node: true }, extends: [ \u0026#34;eslint:recommended\u0026#34;, \u0026#34;plugin:@typescript-eslint/recommended\u0026#34;, \u0026#34;plugin:react-hooks/recommended\u0026#34;, ], parser: \u0026#34;@typescript-eslint/parser\u0026#34;, parserOptions: { ecmaVersion: \u0026#34;latest\u0026#34;, sourceType: \u0026#34;module\u0026#34; }, plugins: [\u0026#34;react-refresh\u0026#34;], rules: { \u0026#34;react-refresh/only-export-components\u0026#34;: \u0026#34;warn\u0026#34;, }, }; 参考链接\n.eslintrc.js \u0026lsquo;module\u0026rsquo; is not defined ","permalink":"http://localhost:1313/eslint-module-not-define/","summary":"\u003cp\u003e使用 vite 新建了一个 react 的项目，通过 vscode 打开，发现 \u003ccode\u003e.eslintrc.cjs\u003c/code\u003e 文件报错：\u0026quot;\u0026lsquo;module\u0026rsquo; is not defined\u0026quot;。经过查阅资料，发现原来是 vscode 的问题。ESLint 本来应该忽略以 \u003ccode\u003e.\u003c/code\u003e 开头的文件，但在 vscode 中没有生效。解决方案就是在 \u003ccode\u003e.eslintrc.cjs\u003c/code\u003e 文件中添加 node 环境。就像这样：\u003c/p\u003e","title":"ESLint 配置文件报错 Module 未定义"},{"content":"本文介绍了两种在 Windows 系统中批量重命名文件的方法。\nEverything 使用 Everything 搜索文件路径，选中文件之后可以直接按 F2 键批量重命名，支持正则表达式。\n例如，电视剧视频文件名很长，我们只想保留需要的部分：\n原文件名：后宫·甄嬛传.Empresses.in.the.Palace.S01E01.2011.2160p.WEB-DL.H265.60FPS.AAC.mp4\n原始文件名表达式：%1.%2.S01E%3.%4.mp4\n新文件名表达式：%1.E%3.mp4\n新文件名：后宫·甄嬛传.E01.mp4\nBat 脚本 以批量去除文件名中的某个字符串为例：\n@echo off set /p str1= 请输入要替换的文件 / 文件夹名字符串（空格亦适用）： set /p str2= 请输入替换后的文件 / 文件夹名字符串（删除则直接回车）： set /p str3= 请选择 仅处理文件（输入1）/ 仅处理文件夹（输入2）/ 均需要处理（输入3）： echo= echo 正在修改中，请稍候……（完成后会自动退出！） ::-----文件----- if %str3% EQU 1 (set decision=\u0026#39;dir /a:-d /b\u0026#39;) ::-----文件夹----- if %str3% EQU 2 (set decision=\u0026#39;dir /a:d /b\u0026#39;) ::-----文件+文件夹----- if %str3% EQU 3 (set decision=\u0026#39;dir /b\u0026#39;) for /f \u0026#34;tokens=* delims=\u0026#34; %%i in (%decision%) do ( if \u0026#34;%%~nxi\u0026#34; neq \u0026#34;%~nx0\u0026#34; ( set \u0026#34;file=%%i\u0026#34; set \u0026#34;name=%%~ni\u0026#34; set \u0026#34;extension=%%~xi\u0026#34; call set \u0026#34;name=%%name:%str1%=%str2%%%\u0026#34; setlocal enabledelayedexpansion ren \u0026#34;!file!\u0026#34; \u0026#34;!name!!extension!\u0026#34; 2\u0026gt;nul endlocal) ) exit 注意，需要使用 GBK 编码保存，否则中文会乱码。放到需要重命名的目录下运行。\n参考链接：\n如何批量去除文件名中的某些字符串？ - Outside 的回答 - 知乎 ","permalink":"http://localhost:1313/windows-batch-rename/","summary":"\u003cp\u003e本文介绍了两种在 Windows 系统中批量重命名文件的方法。\u003c/p\u003e","title":"Windows 批量修改文件名"},{"content":"本文介绍了如何使用 Clang Format 来格式化 C++ 代码。\n由于我平时使用 Java 较多，所以比较偏爱类似于 Java 的格式化风格。即大括号不换行，使用 4 个空格缩进等。\n我的配置文件如下：\n// 基于 LLVM 配置修改 BasedOnStyle: LLVM // 语言 Cpp Language: Cpp // 使用空格而不是 Tab UseTab: Never // 缩进 4 字符 IndentWidth: 4 TabWidth: 4 // 访问修饰符（public）等靠左对齐 AccessModifierOffset: -4 // 最大列宽度 ColumnLimit: 90 // 是否允许短的函数，语句块等单独一行 AllowShortIfStatementsOnASingleLine: Never AllowShortBlocksOnASingleLine: Empty AllowShortFunctionsOnASingleLine: Empty // 函数初始化元素右对齐 AlignArrayOfStructures: Right // 函数返回值类型不换行 AlwaysBreakAfterReturnType: None // 函数定义如果换行函数名需要缩进 IndentWrappedFunctionNames: true // 函数的参数要么在同一行，要么各占一行 BinPackParameters: false AllowAllParametersOfDeclarationOnNextLine: false 效果如下：\n#include \u0026lt;vector\u0026gt; using namespace std; class Solution { public: void backTrack(vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; \u0026amp;ret, vector\u0026lt;int\u0026gt; \u0026amp;cur, const vector\u0026lt;int\u0026gt; \u0026amp;candidates, int index, int sum, int target) { if (sum == target) { ret.emplace_back(cur); return; } else if (sum \u0026gt; target) { return; } else if (index == candidates.size()) { return; } else { cur.emplace_back(candidates[index]); sum += candidates[index]; backTrack(ret, cur, candidates, index, sum, target); sum -= candidates[index]; cur.pop_back(); backTrack(ret, cur, candidates, index + 1, sum, target); } } vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; combinationSum(vector\u0026lt;int\u0026gt; \u0026amp;candidates, int target) { vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; ret; vector\u0026lt;int\u0026gt; cur; int sum = 0; int index = 0; backTrack(ret, cur, candidates, index, sum, target); return ret; } }; ","permalink":"http://localhost:1313/clang-format/","summary":"\u003cp\u003e本文介绍了如何使用 Clang Format 来格式化 C++ 代码。\u003c/p\u003e","title":"C++ Clang Format 设置"},{"content":"在 C 语言中，字符串实际上是使用空字符 \\0 结尾的一维字符数组。C 标准库提供了一系列对于字符串的操作，大多定义在头文件 \u0026lt;string.h\u0026gt; 中。本文对一些常用的字符串操作进行记录。\n1. 初始化字符串 我们可以直接使用数组初始化规则来初始化字符串。注意，C 编译器会在初始化时自动将 \\0 放在字符串的末尾。\nchar str1[12] = \u0026#34;hello\u0026#34;; 2. 输入和输出 我们有两种方法来输入和输出字符串。一种是使用格式化输入输出的 scanf() 和 printf()，另一种是使用 gets() 和 puts()。scanf() 与 gets() 的一个重要区别是 scanf() 遇到空格就会终止，而 gets()会读入完整的一行。函数 puts() 从参数指定的地址开始输出，遇到第一个 \\0 后终止，并自动追加一个换行符。\nchar str1[12]; char str2[12]; scanf(\u0026#34;%s\u0026#34;, str1); prinf(\u0026#34;%s\\n\u0026#34;, str1); gets(str2); puts(str2); 3. 字符串赋值 char *strcpy(char *dest, const char *src) 把 src 所指向的字符串复制到 dest，返回值为一个指向最终的目标字符串 dest 的指针。\nchar *strncpy(char *dest, const char *src, size_t n) 把 src 所指向的字符串复制到 dest，最多复制 n 个字符。当 src 的长度小于 n 时，dest 的剩余部分将用空字节填充，返回值为最终复制的字符串。需要注意的是，如果 src 的长度大于 n，strncpy() 并不会自动加上终止符 \\0，需要手动添加。\nchar str1[14] = \u0026#34;hello, world!\u0026#34;; char str2[14]; char str3[11]; strcpy(str2, str1); strncpy(str3, str1, 10); str3[10] = \u0026#39;\\0\u0026#39;; printf(\u0026#34;str2: %s\\n\u0026#34;, str2); printf(\u0026#34;str3: %s\\n\u0026#34;, str3); 最终结果为：\nstr2: hello, world! str3: hello, wor 4. 字符串连接 char *strcat(char *dest, const char *src) char *strncat(char *dest, const char *src, size_t n) strcat() 把 src 所指向的字符串追加到 dest 所指向的字符串的结尾。strncat() 会将 src 所指向的字符串不多于 n 个字符追加到 dest 所指向的字符串的结尾。其他函数名加 n 的函数与之类似，下面不再一一说明。\nchar str1[20] = \u0026#34;Hello, \u0026#34;; char str2[10] = \u0026#34;Tom\u0026#34;; strcat(str1, str2); printf(\u0026#34;%s\\n\u0026#34;, str1); 结果为\nstr1: Hello, Tom 5. 字符串长度 size_t strlen(const char *str) strlen() 计算字符串 str 的长度，直到空结束字符，但不包括空结束字符。\n6. 字符串比较 int strcmp(const char *str1, const char *str2) int strncmp(const char *str1, const char *str2, size_t n) strcmp() 把 str1 所指向的字符串和 str2 所指向的字符串进行比较。strcmp() 从左至右依次按 ASCII 码对比两个字符串的字符，直至遇到不同的字符或 \\0。返回值为整数，等于 1 表示 str1 \u0026gt; str2， 等于 0 表示 str1 = str2，等于 -1 表示 str1 \u0026lt; str2。\n7. 查找字符 char *strchr(const char *str, int c) char *strrchr(const char *str, int c) strchr() 用于查找字符串中的一个字符，如果在字符串 str 中找到字符 c，则函数返回指向第一次出现的该字符的指针，如果未找到该字符则返回 NULL。strrchr() 则返回指向最后一次出现的该字符的指针。\nchar str[] = \u0026#34;hello\u0026#34;; char ch = \u0026#39;l\u0026#39;; char *ptr1 = strchr(str, ch); char *ptr2 = strrchr(str, ch); printf(\u0026#34;*ptr1 = %s\\n\u0026#34;, ptr1); printf(\u0026#34;*ptr2 = %s\\n\u0026#34;, ptr2); 结果为\n*ptr1 = llo *ptr2 = lo 8. 查找子串 char *strstr(const char *str1, const char *str2) strstr() 返回字符串 str1 中第一次出现 str2 的位置，如果没找到返回 NULL。\nchar str1[] = \u0026#34;hello\u0026#34;; char str2[] = \u0026#34;ll\u0026#34;; char *ptr = strstr(str1, str2); printf(\u0026#34;*ptr = %s\\n\u0026#34;, ptr); 结果为\n*ptr = llo 9. 字符串转换为数值 字符串与数值转换的函数定义在头文件 \u0026lt;stdlib.h\u0026gt; 中。\ndouble atof(const char *str) int atoi(const char *str) long int atol(const char *str) atof 将 str 转换为一个浮点数，atoi 将 str 转换为一个整数，atol 将 str 转换为一个长整数。\nchar str[] = \u0026#34;123.4\u0026#34;; int a = atoi(str); double b = atof(str); printf(\u0026#34;a = %d\\n\u0026#34;, a); printf(\u0026#34;b = %.1lf\\n\u0026#34;, b); 结果为\na = 123 b = 123.4 10. 字符检查 \u0026lt;ctype.h\u0026gt; 头文件定义了一系列的字符检查函数。\n// 该函数检查所传的字符是否是字母和数字。 int isalnum(int c) // 该函数检查所传的字符是否是字母。 int isalpha(int c) // 该函数检查所传的字符是否是控制字符。 int iscntrl(int c) // 该函数检查所传的字符是否是十进制数字。 int isdigit(int c) // 该函数检查所传的字符是否是十六进制数字。 int isxdigit(int c) // 该函数检查所传的字符是否是小写字母。 int islower(int c) // 该函数检查所传的字符是否是大写字母。 int isupper(int c) // 该函数检查所传的字符是否是标点符号字符。 int ispunct(int c) // 该函数检查所传的字符是否是空白字符。 int isspace(int c) // 该函数检查所传的字符是否有图形表示法。 int isgraph(int c) // 该函数检查所传的字符是否是可打印的。 int isprint(int c) 其中，字母数字字符包含数字、小写字母和大写字母；空白字符包含制表符、换行符、垂直制表符、换页符、回车符和空格符；图形字符包含字母数字字符和标点符号字符；可打印字符包含字母数字字符、标点符号字符和空白字符；控制字符包含 ASCII 编码的八进制代码从 000 到 037，以及 177（DEL）的字符。\n另外，标准库还包含两个转换函数\n// 该函数把大写字母转换为小写字母。 int tolower(int c) // 该函数把小写字母转换为大写字母。 int toupper(int c) 对于 tolower()，如果 c 有相对应的小写字母，则该函数返回 c 的小写字母，否则返回 c 的原值。toupper() 与之类似。\n","permalink":"http://localhost:1313/c-string/","summary":"\u003cp\u003e在 C 语言中，字符串实际上是使用空字符 \\0 结尾的一维字符数组。C 标准库提供了一系列对于字符串的操作，大多定义在头文件 \u0026lt;string.h\u0026gt; 中。本文对一些常用的字符串操作进行记录。\u003c/p\u003e","title":"C 语言字符串操作"},{"content":"本文记录了一些常见的公共 DNS，包括 DoH 以及 IPv6 DNS。\nDoH (DNS over HTTPS) 阿里云\nhttps://223.5.5.5/dns-query DNSPod\nhttps://doh.pub/dns-query Cloudflare\nhttps://1.1.1.1/dns-query Google\nhttps://dns.google/dns-query IPv6 DNS 阿里云\n2400:3200::1 DNSPod\n2402:4e00:: Cloudflare\n2606:4700:4700::1111 Google\n2001:4860:4860::8888 ","permalink":"http://localhost:1313/public-dns/","summary":"\u003cp\u003e本文记录了一些常见的公共 DNS，包括 DoH 以及 IPv6 DNS。\u003c/p\u003e","title":"公共 DNS 推荐"},{"content":"适用于 Linux 的 Windows 子系统，即 WSL，为使用 Windows 系统的程序员提供了一个便利的 GNU/Linux 环境。不过之前由于 WSL2 并不支持 systemd，所以当我们需要在 WSL 中起一些服务时就很不方便。好在现在 WSL2 已经原生支持了 systemd，本文就对如何安装 WSL2 和启用 systemd 进行简要的介绍。\n安装 WSL2 现在，可以使用单个命令安装运行 WSL 所需的一切内容。 在管理员模式下打开 PowerShell 或 Windows 命令提示符，输入 wsl \u0026ndash;install 命令，然后重启计算机。\nwsl --install 这会启用“虚拟机平台”以及“适用于 Linux 的 Windows 子系统”功能，并安装 Ubuntu 为 WSL2 的默认发行版。\n重启后系统会自动安装并启动 Ubuntu，我们需要设置用户名及密码。\n安装完成后，我们可以在 powershell 里查看 WSL 中发行版的版本。\n\u0026gt; wsl -l -v NAME STATE VERSION * Ubuntu Running 2 我们可以看到运行的 Ubuntu 已经是 WSL2 版本。\n启用 systemd 在 WSL 中修改 /etc/wsl.conf 文件\n[boot] systemd=true 然后在 powershell 中重启 WSL。\nwsl.exe --shutdown 重启后可以在 WSL 中进行验证\nps --no-headers -o comm 1 如果返回 systemd 说明启用成功。\n我们现在就可以通过 systemd 来管理服务了。例如开机自启动 docker\nsudo systemctl enable docker.service 添加用户组\nsudo usermod -aG docker $USER 我们还可以通过输入命令来查看 systemd 管理的服务状态。\nsystemctl list-unit-files --type=service 限制 WSL2 资源占用 WSL2 默认会占用系统一半的内存，我们可以通过配置文件来限制 WSL2 占用的资源。\n修改 Windows 用户目录下 .wslconfig 文件，例如\n[wsl2] processors=4 memory=2GB swap=2GB 限制 WSL2 使用 4 核处理器，2GB 内存以及 2GB 的交换空间。\n","permalink":"http://localhost:1313/wsl2-systemd/","summary":"\u003cp\u003e适用于 Linux 的 Windows 子系统，即 WSL，为使用 Windows 系统的程序员提供了一个便利的 GNU/Linux 环境。不过之前由于 WSL2 并不支持 systemd，所以当我们需要在 WSL 中起一些服务时就很不方便。好在现在 WSL2 已经原生支持了 systemd，本文就对如何安装 WSL2 和启用 systemd 进行简要的介绍。\u003c/p\u003e","title":"在 WSL2 中启用 Systemd"},{"content":"JSON Web Token（简写为 JWT）是目前最流行的跨域认证解决方案。本文简要介绍了它的原理和用法。\nJWT 的结构 JWT 由三个部分组成\nHeader （头部） Payload （负载） Signature （签名） 其中 Header 和 Payload 部分需要通过 Base64URL 算法编码成字符串。\n下面是一个 JWT 的样例\n三部分分别用红色、紫色和蓝色来标明。\nHeader Header 表明了使用什么签名算法，如上例\n{ \u0026#34;alg\u0026#34;: \u0026#34;RS256\u0026#34; } 表明该 JWT 使用 RS256 签名算法。\nPayload Payload 用来存放需要传输的数据。JWT 官方规定了 7 个字段，可供选用。\niss (issuer)：签发人 exp (expiration time)：过期时间 sub (subject)：主题 aud (audience)：受众 nbf (Not Before)：生效时间 iat (Issued At)：签发时间 jti (JWT ID)：编号 除此之外，我们还可以定义私有字段。如上例\n{ \u0026#34;iss\u0026#34;: \u0026#34;self\u0026#34;, \u0026#34;sub\u0026#34;: \u0026#34;Tom\u0026#34;, \u0026#34;exp\u0026#34;: 1669595177, \u0026#34;iat\u0026#34;: 1669559177, \u0026#34;scope\u0026#34;: \u0026#34;ROLE_USER\u0026#34; } subject 设置为用户名 Tom，签发时间和过期时间使用一个 UNIX 时间戳，并通过 scope 字段表明 Tom 的角色权限为 ROLE_USER。\nSignature Signature 部分是对前两部分的签名，防止数据篡改。\n如 RS256 签名算法为\nRSASHA256( base64UrlEncode(header) + \u0026#34;.\u0026#34; + base64UrlEncode(payload), publicKey, privateKey ) 算出签名以后，把 Header、Payload、Signature 三个部分拼成一个字符串，每个部分之间用 \u0026ldquo;.\u0026rdquo; 分隔，返回给用户。\nJWT 的使用方式 当客户端收到服务器发送的 JWT 之后，就可以将其储存起来。此后，客户端每次与服务端通信，都需要携带这个 JWT 作为身份证明。一般的方法是放在 HTTP 请求的头部:\nAuthorization: Bearer \u0026lt;token\u0026gt; 当此 JWT 过期之后就需要申请新的 JWT。\nJWT 密钥生成 Spring Security 的 JWT 登录默认使用 RS256 签名算法，并要求公私钥为 PKCS#8 格式。我们可以通过 openssl 来生成密钥。\n如果使用的是老版本的 openssl （如 1.1.1)，那么默认生成私钥的为 PKCS#1 格式，需要我们转换成 PKCS#8 格式。\nopenssl genrsa -out private.key openssl rsa -in private.key -pubout app.pub openssl pkcs8 -topk8 -in private.key -nocrypt -out app.key 而如果我们使用的是新版本的 openssl （如 3.0.x），那么默认生成的密钥就是 PKCS#8 格式。\nopenssl genrsa -out app.key openssl rsa -in app.key -pubout app.pub ","permalink":"http://localhost:1313/introduction-to-jwt/","summary":"\u003cp\u003eJSON Web Token（简写为 JWT）是目前最流行的跨域认证解决方案。本文简要介绍了它的原理和用法。\u003c/p\u003e","title":"JWT 登录简介"},{"content":"本文主要介绍了 Kotlin 如何使用 Spring Data JPA 来操作 PostgreSQL 数据库。\nSpring Data JPA 介绍 Spring Data JPA 是一个流行的 Java (Kotlin) ORM 库，也是 Spring 大家庭的一员。JPA 力图通过面向对象（Object Oriented）的思想来操作数据库，以减少实现数据访问层（DAO）的工作量。我们只需定义存储库接口，Spring 就会自动提供实现。\nJPA 基本使用 在使用 JPA 之前，首先要进行相关信息的配置。修改 application.properties 文件\n# postgres spring.datasource.url=jdbc:postgresql://localhost:5432/bookstore spring.datasource.username=postgres spring.datasource.password=1234 spring.datasource.driver-class-name=org.postgresql.Driver # jpa spring.jpa.hibernate.ddl-auto=update spring.jpa.show-sql=true spring.jpa.properties.hibernate.format_sql=true spring.jpa.database-platform=org.hibernate.dialect.PostgreSQLDialect postgres 部分定义了数据库的地址，用户名和密码，以及数据库的驱动。而 JPA 部分则定义了 JPA 运行时的一些行为，比如在启动时如何更新表结构等。\n我们首先定义实体类。创建文件 User.kt\n@Entity @Table(name = \u0026#34;\\\u0026#34;user\\\u0026#34;\u0026#34;) class User { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = \u0026#34;id\u0026#34;, nullable = false) var id: Long? = null @Column(name = \u0026#34;username\u0026#34;, nullable = false) var username: String @Column(name = \u0026#34;password\u0026#34;, nullable = false) var password: String } @Entity 注解表明这是一个实体类，而 @Table 标注表名。注意表名 user 的前后加了转义后的双引号，是因为 user 是 PostgreSQL 里的保留字，这样才能成功建表。\n表的字段首先是主键 id，用 @Id 注解表明。@GeneratedValue 表明了主键的生成策略，这里选择 IDENTITY，即由数据库生成自增主键。@Colume 注解表明字段名以及该字段是否可为 null。后面的两个字段 username 和 password 也类似，这样就定义了一个有三个字段的表。\nid username password 1 abc 123456 接下来我们定义数据访问接口。创建文件 UserRepository.kt\ninterface UserRepository : JpaRepository\u0026lt;User, Long\u0026gt; { // 根据用户名查询 fun findByUsername(username: String): User? // 根据用户名计数 fun countByUsername(username: String): Long } 这样就定义好了两个查询方法，分别是根据用户名来查询用户和根据用户名来计数。除此之外，JPA 还默认生成了 findById() 方法，只不过它返回的结果并不是我们定义的 User 类，而是一个 Optional 对象，需要进一步的操作才能取出对象。\n上面介绍了“增删改查”中的查，JPA 的 “增、改”操作都是由 save() 方法实现，“删”是由 delete() 方法实现。下面举个例子来说明如何使用 JPA 来操作数据库。\n// 根据用户名查询 val user1 = userRepository.findByUsername(\u0026#34;abc\u0026#34;) // 修改密码 user1.password = \u0026#34;654321\u0026#34; userRepository.save(user1) // 根据主键查询 val user2 = userRepository.findById(\u0026#34;def\u0026#34;).orElse(null) // 删除用户 userRepository.delete(user2) // 根据用户名计数 val count = userRepository.countByUsername(\u0026#34;ghi\u0026#34;) JPA 关系映射 上面介绍了 JPA 的基本用法，下面介绍如何用 JPA 实现数据表之间的映射关系，即一对一，一对多和多对多关系。\n@OneToOne 一对一是最简单的映射关系。例如一个人只有一张身份证，而一张身份证对应一个人。一对一关系可以由任何一方来维护。\n// 公民表 @Entity @Table(name = \u0026#34;Person\u0026#34;) class Person { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = \u0026#34;id\u0026#34;, nullable = false) var id: Long? = null @OneToOne var idCard: IdCard? = null } // 身份证表 @Entity @Table(name = \u0026#34;IdCard\u0026#34;) class IdCard { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = \u0026#34;id\u0026#34;, nullable = false) var id: Long? = null @OneToOne(mappedBy = \u0026#34;idCard\u0026#34;) var person? = null } mappedBy 表明这个一对一关系由 Person 表维护。\n@OneToMany 一对多关系也很常见，例如书籍和出版社的关系。每本书籍只有一个出版社，而一个出版社对应很多本书籍。一对多关系通常由多的那一方来维护。\n// 书籍表 @Entity @Table(name = \u0026#34;Book\u0026#34;) class Book { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = \u0026#34;id\u0026#34;, nullable = false) var id: Long? = null @ManyToOne var press: Press? = null } // 出版社表 @Entity @Table(name = \u0026#34;Press\u0026#34;) class Press { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = \u0026#34;id\u0026#34;, nullable = false) var id: Long? = null @OneToMany(mappedBy = \u0026#34;press\u0026#34;) var books: MutableSet\u0026lt;Book\u0026gt; = mutableSetOf() } 这样 Press 的主键会作为一个字段插入到 Book 表中。Book 表就像这样\nid press_id 1 2 而如果我们指定让一的一方维护关系的话，就需要一个中间表来存储关系，增大了系统的复杂度。\n@ManyToMany 书籍和作者的关系是一种典型的多对多关系。每本书籍可以有多个作者，而每个作者也可以对应多本书籍。多对多关系可以由双方的任一方来维护。多对多关系需要一个中间表来存储。\n// 书籍表 @Entity @Table(name = \u0026#34;book\u0026#34;) class Book { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = \u0026#34;id\u0026#34;, nullable = false) var id: Long? = null @ManyToMany(fetch = FetchType.EAGER) @JoinTabler name = \u0026#34;book_author\u0026#34;, joinColumns = [JoinColumn(name = \u0026#34;book_id\u0026#34;)], inverseJoinColumns = [JoinColumn(name = \u0026#34;author_id\u0026#34;)] ) var authors: MutableSet\u0026lt;Author\u0026gt; = mutableSetOf(), } // 作者表 @Entity @Table(name = \u0026#34;author\u0026#34;) class Author { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = \u0026#34;id\u0026#34;, nullable = false) var id: Long? = null @ManyToMany(mappedBy = \u0026#34;authors\u0026#34;) var books: MutableSet\u0026lt;Book\u0026gt; = mutableSetOf(), } 这样就会创建一个名为 \u0026ldquo;book_author\u0026rdquo; 的中间表来存储 Book 和 Author 的关系，表的内容为 Book 和 Author 的主键。\nbook_id author_id 3 5 @ElementCollection 下面以“商品-订单”关系来介绍一种相对复杂的映射关系。在订单中有多种商品，而每个商品又有着不同的数量，这时可以通过 @ElementCollecion 和 MapKeyJoinColumn 来实现。\n// 商品表 @Entity @Table(name = \u0026#34;product\u0026#34;) class Product { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = \u0026#34;id\u0026#34;, nullable = false) var id: Long? = null } //订单表 @Entity @Table(name = \u0026#34;\\\u0026#34;order\\\u0026#34;\u0026#34;) class Order { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = \u0026#34;id\u0026#34;, nullable = false) var id: Long? = null @ElementCollection @CollectionTable( name = \u0026#34;order_product\u0026#34;, joinColumns = [JoinColumn(name = \u0026#34;product_id\u0026#34;)] ) @Column(name = \u0026#34;product_amount\u0026#34;) @MapKeyJoinColumn(name = \u0026#34;order_id\u0026#34;) var products: MutableMap\u0026lt;product, Int\u0026gt; = mutableMapOf() } 这样也会创建一个名为 \u0026ldquo;order_product\u0026rdquo; 的中间表来存储订单中各类商品的数量关系，表的内容为\norder_id product_id product_amount 1001 2050 3 1001 2077 2 添加索引 我们可以使用 @Table 注解来添加索引。如\n@Entity @Table( name = \u0026#34;book\u0026#34;, indexes = [ Index(name = \u0026#34;idx_name\u0026#34;, columnList = \u0026#34;name\u0026#34;, unique = false), Index(name = \u0026#34;uni_isbn\u0026#34;, columnList = \u0026#34;isbn\u0026#34;, unique = true), ] ) class Book { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = \u0026#34;id\u0026#34;, nullable = false) var id: Long? = null @Column(name = \u0026#34;name\u0026#34;, nullable = false) var name: String, @Column(name = \u0026#34;isbn\u0026#34;, nullable = false) var isbn: String, } 上面为 Book 表添加了两条索引，分别是对于书籍名字的普通索引和对于 ISBN 编号的唯一索引。通过索引可以大大提高数据的查询速度。\n开启审计 JPA 的审计功能可以方便地记录数据项的创建时间和最后修改时间，只需要在实体类上添加 @EntityListeners 注解。\n@Entity @Table(name = \u0026#34;\\\u0026#34;user\\\u0026#34;\u0026#34;) @EntityListeners(AuditingEntityListener::class) class User { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = \u0026#34;id\u0026#34;, nullable = false) var id: Long? = null @CreatedDate @Column(name = \u0026#34;created_time\u0026#34;, nullable = false) var createdTime: LocalDateTime? = null @LastModifiedDate @Column(name = \u0026#34;modified_time\u0026#34;, nullable = false) var modifiedTime: LocalDateTime? = null } 实体类继承 如果我们想要所有的实体类都继承自一个基类的话，可以使用 MappedSuperclass 注解。\n被该注解标注的类不会在数据库中创建单独的表，但该类所拥有的属性都将映射到其子类的数据库表的字段中。\n例如\n// 基类 @MappedSuperclass class BaseEntity { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = \u0026#34;id\u0026#34;, nullable = false) var id: Long? = null } // 用户表 @Entity @Table(name = \u0026#34;\\\u0026#34;user\\\u0026#34;\u0026#34;) class User: BaseEntity() { @Column(name = \u0026#34;username\u0026#34;, nullable = false) var username: String @Column(name = \u0026#34;password\u0026#34;, nullable = false) var password: String } 这样 User 表就有三个字段，分别是 id，username 以及 password。\nKotlin All-open 插件 由于 Spring AOP 的设计，所有 Spring 相关的类都需要是 open 的。我们可以使用 all-open 插件来方便地解决这一问题。\nall-open 插件默认支持以下注解：\n@Component @Async @Transactional @Cacheable @SpringBootTest 由于 @Component 是 @Configuration、@Controller、@RestController、@Service 以及 @Repository 的元注解，所以以上注解也都默认为 open。\n所以，我们只需要在插件中添加 JPA 相关注解就可以了。\n修改 build.gradle.kts 文件\nallOpen { annotation(\u0026#34;jakarta.persistence.MappedSuperclass\u0026#34;) annotation(\u0026#34;jakarta.persistence.Entity\u0026#34;) } ","permalink":"http://localhost:1313/spring-data-jpa-relationship/","summary":"\u003cp\u003e本文主要介绍了 Kotlin 如何使用 Spring Data JPA 来操作 PostgreSQL 数据库。\u003c/p\u003e","title":"Spring Data JPA 介绍"},{"content":"Arch Linux 是一个著名的滚动更新（Rolling update）的 Linux 发行版。与常用的 Ubuntu 等发行版相比，Arch Linux 有着更新的软件包，并且由于滚动更新的缘故，Arch Linux 也避免了 Ubuntu 在大版本更新时（如 20.04 LTS 到 22.04 LTS）由于软件包版本差异过大而可能遇到的困难。不过，当很多新人打算尝试 Arch Linux 的时候，却直接被 Arch Linux 复杂的安装过程而劝退。不过，随着官方系统镜像集成了 archinstall，Arch Linux 的安装也成为了一件简单的事情。\n本文通过创建一个 VMware 的虚拟机的方式来介绍 Arch Linux 的安装流程，在真机上的安装流程也类似。首先是准备工作，下载 Arch Linux 的安装 ISO 镜像，如果是真机安装的话可以使用 rufus 软件制作启动盘。\n然后启动机器，进入 LiveCD。然后输入命令进入 archinstall 的可视化安装界面。\nroot@archiso ~ # archinstall 然后就可以看到安装的指引界面。\n接着我们从上到下依次进行设置。\n语言和键盘布局 由于 archinstall 暂不支持中文，因此这两项可以跳过。 镜像区域 选择 China locale 编码 选择 zh_CN.UTF8 磁盘 选择磁盘然后设置分区。选择抹除选择的磁盘，然后选择文件系统，有 btrfs，ext4，f2fs 和 xfs。可以根据自己的需要选择，这里选择 xfs。然后选择是否划分单独的 /home 分区，这里选择否。下面的硬盘加密如无特殊需求可跳过。grub 引导和 swap 都默认设置好了，如无特殊需求也可跳过。 设置主机名和 root 密码 主机名根据个人喜好设置，root 密码如不需要可留空。 添加用户 选择添加用户，输入用户名和密码，并确认密码，选择该用户是否是超级用户即具有 sudo 权限，选择是。确认并退出。 配置网络 上面的内核设置等如无特殊需要可以跳过，下面配置网络。如果打算安装桌面环境，选择使用 NetworkManager，如果用作服务器，选择手动配置。这里选择手动配置，添加网卡，选择通过 DHCP 获取 IP 还是静态 IP。选择静态 IP，输入 IP 地址和子网掩码，即 CIDR 地址，如 192.168.0.5/24。接着输入网关地址和 DNS 地址。确认并退出。 时区 选择 Asia/Shanghai，可以使用 / 来搜索。NTP 默认开启可以跳过。 现在一切准备就绪，选择 Install 来安装。按 Enter 键确认。之后就等待安装完成。\n安装完成后会询问是否 chroot 到新安装的系统，选择是。进入系统之后就可以先安装一些需要的软件，如 vim，openssh 等。\npacman -S vim git openssh neofetch 并开启 sshd 的自启动，以便之后通过 ssh 来进行操作。\nsystemctl enable sshd 然后，我们只需要输入 exit 退出，并输入 reboot 来重启系统就可以完成安装了。\n重启后，通过 ssh 连接到刚刚创建的用户，就可以开始使用了。以新系统的 neofetch 信息作结。\n","permalink":"http://localhost:1313/install-archlinux-using-archinstall/","summary":"\u003cp\u003eArch Linux 是一个著名的滚动更新（Rolling update）的 Linux 发行版。与常用的 Ubuntu 等发行版相比，Arch Linux 有着更新的软件包，并且由于滚动更新的缘故，Arch Linux 也避免了 Ubuntu 在大版本更新时（如 20.04 LTS 到 22.04 LTS）由于软件包版本差异过大而可能遇到的困难。不过，当很多新人打算尝试 Arch Linux 的时候，却直接被 Arch Linux 复杂的安装过程而劝退。不过，随着官方系统镜像集成了 archinstall，Arch Linux 的安装也成为了一件简单的事情。\u003c/p\u003e","title":"使用 archinstall 便捷安装 Arch Linux"},{"content":"高阶函数，就是以函数作为参数或是返回值的函数，是函数式编程的基本思想之一，在众多编程语言中都有实现。本文以 JavaScript 语言为例介绍了对于数组的一系列高阶函数，包括 map, reduce, filter, sort 等。\nmap map() 的效果是将一个函数作用于数组的每一个元素，并返回一个新的数组。\n例如，f(x) = x^2，要把这个函数作用于数组[1, 2, 3, 4, 5]，就可以使用 map\nfunction pow(x) { return x * x; } const a = [1, 2, 3, 4, 5]; const b = a.map(pow); console.log(b); 当然，也可以使用箭头函数来简化代码\nconst a = [1, 2, 3, 4, 5]; const b = a.map((x) =\u0026gt; x * x); console.log(b); 得到结果 [1, 4, 9, 16, 25]。\nreduce reduce() 的效果是对数组的每一个元素按序执行 reduce 函数，每次执行 reduce 都会将先前元素的计算结果作为参数传入，最后将其结果返回为单个值。\n例如对数组 [1, 2, 3, 4, 5] 求和\nconst a = [1, 2, 3, 4, 5]; const b = a.reduce((sum, x) =\u0026gt; sum + x, 0); console.log(b); 得到结果 15。\nreduce() 接收两个参数，第一个参数是一个 reduce 函数，第二个参数是初始值。如上文的 reduce 函数是将当前值依次累加到前面所有数的和上，而初始值被设为 0。\n如果不传递初始值，那么 reduce 会将第一个元素作为初始值，而 reduce 函数将会从第二个元素开始执行。在本问题中，这两种写法得到的结果是一致的。\nconst a = [1, 2, 3, 4, 5]; const b = a.reduce((sum, x) =\u0026gt; sum + x); console.log(b); filter filter() 正如它的名字过滤器，输入一个函数，筛选出符合条件的元素，返回一个新的数组。\n例如过滤出 [1, 2, 3, 4, 5] 中的奇数\nconst a = [1, 2, 3, 4, 5]; const b = a.filter((x) =\u0026gt; x % 2 === 1); console.log(b); 得到结果 [1, 3, 5]。\nsort sort() 接收一个比较函数，对数组进行原地排序。sort() 的默认行为是将元素转换为字符串，然后比较它们的 UTF-16 值。\n例如，对 [10, 20, 1, 2] 进行排序\nconst a = [10, 20, 1, 2]; a.sort(); console.log(a); 得到结果 [1, 10, 2, 20]，这就是按照字符串编码排序得到的。\n而如果想要按数值的升序排序，可以传入一个比较函数。比较函数的规则是\ncompare(a, b) 返回值 排序顺序 \u0026gt; 0 a 在 b 后 \u0026lt; 0 a 在 b 前 === 0 保持 a 和 b 的顺序不变 因此，可以通过 a - b 来方便地使数组按从小到大排列。\nconst a = [10, 20, 1, 2]; a.sort((x, y) =\u0026gt; x - y); console.log(a); 这时得到结果 [1, 2, 10, 20]。\nevery every() 类似于 filter()，输入一个函数，检验数组的每一个元素是否都满足条件。\n例如，检验数组元素是否都是偶数\nconst arr1 = [1, 2, 3, 4]; const arr2 = [2, 4, 6, 8]; const b1 = arr1.every((x) =\u0026gt; x % 2 === 0); const b2 = arr2.every((x) =\u0026gt; x % 2 === 0); console.log(b1); console.log(b2); 得到结果分别为 false, true。\nfind find() 返回符合条件的第一个元素，如果找到了，返回这个元素，如果没找到，返回 undefined。\nconst a = [1, 2, 3, 4]; const b = a.find((x) =\u0026gt; x \u0026gt; 2); console.log(b); 返回 3。\nfindIndex findIndex() 类似于 find()，只不过返回的是符合条件的第一个元素的索引，如果没找到，返回 -1。\nforEach forEach() 类似于 map()，也会对每一个元素执行一次给定的函数，不过它不会返回一个新的数组，一般情况下也不会改变原数组元素的值。因此 forEach() 常用于数组元素的遍历。\n例如打印数组中的每个元素。\nconst a = [1, 2, 3, 4, 5]; a.forEach((x) =\u0026gt; console.log(x)); 输出 1 2 3 4 5\n","permalink":"http://localhost:1313/javascript-functional-programming/","summary":"\u003cp\u003e高阶函数，就是以函数作为参数或是返回值的函数，是函数式编程的基本思想之一，在众多编程语言中都有实现。本文以 JavaScript 语言为例介绍了对于数组的一系列高阶函数，包括 map, reduce, filter, sort 等。\u003c/p\u003e","title":"JavaScript 高阶函数介绍"},{"content":"本文介绍了如何部署后端 Spring Boot 前端 React 的前后端分离项目。\n前端构建 打开前端项目，输入 pnpm build 构建生成 dist 文件夹。然后将该文件夹上传到服务器上，移动到 Nginx 的网站根目录中，默认为 /usr/share/nginx/html。\n后端构建 使用 IDEA 打开后端项目，打开 gradle 工具栏，选择 Task -\u0026gt; build -\u0026gt; bootJar，就会在 /build/libs/ 目录生成 jar 包。\n然后将 jar 上传到服务器，输入命令使其后台运行并生成日志。\nnohup java -jar project.jar \u0026gt; msg.log 2\u0026gt;\u0026amp;1 2\u0026gt;\u0026amp;1 的意思是将标准错误 2 重定向到标准输出 \u0026amp;1 ，标准输出 \u0026amp;1 再被重定向输入到 msg.log 文件中。\n可以通过 jobs 命令查看后台运行的进程。 输入 kill -9 pid 来终止进程。\n反向代理 要解决前后端分离的跨域问题，就需要使用 Nginx 做反向代理。在 前文 中我们使用 Vite 解决了开发时的跨域问题，现在使用 Nginx 解决部署时的跨域问题。\n修改 /etc/nginx/nginx.conf\nserver { listen 80; server_name localhost; location / { root /usr/share/nginx/html; index index.html index.htm; } # 反向代理 location /api/ { rewrite ^/api/(.*)$ /$1 break; proxy_pass http://localhost:8080; } } 这样所有到 80 端口 /api 的请求都会被转发到后端的 8080 端口。在浏览器访问时就不再存在跨域的问题。\n另注：Nginx 的网站目录最好不要设置在个人账户的家目录中，因为 Nginx 默认使用的 http 账户不能读取家目录的内容，会引起 403-Forbidden 权限错误。\n现在，项目部署完成，就可以访问了。\n","permalink":"http://localhost:1313/spring-boot-deployment/","summary":"\u003cp\u003e本文介绍了如何部署后端 Spring Boot 前端 React 的前后端分离项目。\u003c/p\u003e","title":"Spring Boot 前后端分离项目部署"},{"content":"本文介绍了 Chrome 中的一个类 Vim 按键扩展 Vimium C 的基本使用方法。\n滚动屏幕 效果 快捷键 向下滚动 j 向上滚动 K 向下滚动半屏 d 向上滚动半屏 u 滚动到顶部 gg 滚动到底部 G 向左滚动 h 向右滚动 l 操作标签页 效果 快捷键 跳到左侧标签页 J 跳到右侧标签页 K 关闭当前标签页 x 恢复刚关闭的标签页 X 前进 H 后退 L 打开新标签页 t 刷新当前页 r 跳到第一个标签页 g0 跳到最后一个标签页 g$ 返回前一个标签页 ^ 其他操作 效果 快捷键 下一页 ]] 上一页 [[ 复制当前网址 yy 文本框选择 gi 在当前页查找 / 上一处 N 下一处 n 打开链接 f 在新标签页打开链接 F 多功能搜索框 o 参考链接：\nVimium C ","permalink":"http://localhost:1313/chrome-vimium-c/","summary":"\u003cp\u003e本文介绍了 Chrome 中的一个类 Vim 按键扩展 Vimium C 的基本使用方法。\u003c/p\u003e","title":"Chrome 扩展 Vimium C 介绍"},{"content":"本文主要介绍了如何在 Docker 中设置代理加速访问，以及一些基本操作和常用镜像的使用。\nDocker 基本操作 在介绍各种基本指令之前，首先介绍如何通过添加用户组的方式来避免每次命令都需要输入 sudo\nsudo usermod -aG docker $USER 重启系统后，我们的用户就在 docker 用户组中了。\n镜像 Docker 把应用程序及其依赖，打包在 image 文件里面。只有通过这个文件，才能生成 Docker 容器。image 文件可以看作是容器的模板。Docker 根据 image 文件生成容器的实例。同一个 image 文件，可以生成多个同时运行的容器实例。\n列出所有 image 文件 docker image ls # 或者 docker images 获取 image docker pull redis 默认 tag 为 latest，也可以自定义\ndocker pull redis:7.0.4 删除 image docker image rm [image_id] ## 或者 docker rmi [image_id] 容器 列出容器 列出所有运行的容器\ndocker container ls ## 或者 docker ps 列出所有容器，包括终止的容器\ndocker container ls --all ## 或者 docker ps --all 容器的运行和停止 运行容器（-d 为后台运行）\ndocker run -d --name test-redis redis 停止容器\ndocker stop test-redis 启动停止的容器\ndocker start test-redis 删除容器 docker rm [container_id] 设置代理 Docker 守护程序在其启动环境中使用 HTTP_PROXY、HTTPS_PROXY 和 NO_PROXY 环境变量来配置 HTTP 或 HTTPS 代理。我们需要在 Docker systemd 服务文件中添加这些配置。\n创建配置文件\nsudo mkdir -p /etc/systemd/system/docker.service.d sudo vim /etc/systemd/system/docker.service.d/http-proxy.conf 并修改其内容为\n[Service] Environment=\u0026#34;HTTP_PROXY=http://192.168.60.1:7890\u0026#34; Environment=\u0026#34;HTTPS_PROXY=http://192.168.60.1:7890\u0026#34; Environment=\u0026#34;NO_PROXY=localhost,127.0.0.1\u0026#34; 完成修改并重启 docker\nsudo systemctl daemon-reload sudo systemctl restart docker 常用镜像使用 postgres 运行容器\ndocker run --name student-pg -d --restart=unless-stopped -e POSTGRES_PASSWORD=1234 -p 5432:5432 postgres 进入数据库\ndocker exec -it student-pg /bin/bash psql -U postgres 创建数据库\ncreate database student; 查看数据库\n\\l redis docker run --name student-redis -d --restart=unless-stopped -p 6379:6379 redis nginx docker run --name student-nginx -d --restart=unless-stopped -p 80:80 nginx mysql docker run --name student-mysql -d --restart=unless-stopped -p 3306:3306 -e MYSQL_ROOT_PASSWORD=1234 mysql ","permalink":"http://localhost:1313/docker-proxy-configure/","summary":"\u003cp\u003e本文主要介绍了如何在 Docker 中设置代理加速访问，以及一些基本操作和常用镜像的使用。\u003c/p\u003e","title":"Docker 基本操作及代理设置"},{"content":"PostgreSQL 是一个强大的、开源的对象关系型数据库系统，经过 30 多年的积极开发，它在可靠性、功能稳健性和性能方面赢得了良好的声誉。本文记录了如何在 Arch Linux 上安装并配置 PostgreSQL 数据库。\n安装 PostgreSQL 首先就是更新系统并安装 PG 包\nsudo pacman -Syu sudo pacman -S postgresql 然后设置 PG 开机自启\nsudo systemctl enable postgresql.service 不过，这时如何我们尝试启动 PG 服务的话就会报错，提示我们还没有初始化数据库。所以我们就根据提示来初始化数据库\nsu - postgres -c \u0026#34;initdb --locale zh_CN.UTF-8 -D \u0026#39;/var/lib/postgres/data\u0026#39;\u0026#34; 这样就可以启动 PG 了。\nsudo systemctl start postgresql.service 然后就可以连接数据库了。\npsql -U postgres 为数据库设置密码 首先修改 /var/lib/postgres/data/pg_hba.conf，设置认证方式为 scram-sha-256\n# TYPE DATABASE USER ADDRESS METHOD # \u0026#34;local\u0026#34; is for Unix domain socket connections only local all user scram-sha-256 然后修改 /var/lib/postgres/data/postgresql.conf\npassword_encryption = scram-sha-256 重启服务\nsudo systemctl restart postgresql.service 最后修改用户密码\nALTER USER postgres WITH ENCRYPTED PASSWORD \u0026#39;password\u0026#39;; PostgreSQL 常用命令 # 列出所有数据库 \\l # 连接数据库 \\c dbname # 或直接指定数据库名 psql -U postgres dbname # 列出所有表格 \\dt # 显示指定表格信息 \\d tablename ","permalink":"http://localhost:1313/archlinux-install-postgresql/","summary":"\u003cp\u003ePostgreSQL 是一个强大的、开源的对象关系型数据库系统，经过 30 多年的积极开发，它在可靠性、功能稳健性和性能方面赢得了良好的声誉。本文记录了如何在 Arch Linux 上安装并配置 PostgreSQL 数据库。\u003c/p\u003e","title":"Arch Linux 安装 PostgreSQL 数据库"},{"content":"本文主要介绍了如何在 Kotlin 的 Gradle 项目中使用阿里云的 Maven 仓库加速。\n修改编译仓库地址 第一步是修改项目依赖的仓库地址。这也是网上的很多教程中所讲到的内容，在 Maven 中心仓库和本地仓库之前添加阿里云的镜像仓库。\n修改 build.gradle.kts 文件\nrepositories { maven { url = uri(\u0026#34;https://maven.aliyun.com/repository/public/\u0026#34;) } mavenLocal() mavenCentral() } 修改插件仓库地址 第二步就是本文的重头戏了。在修改了上文的仓库地址后，我们会发现大部分的请求还是没有走阿里云的镜像。通过查阅官方文档，我发现原来这些是属于 Gradle 的插件，仓库地址需要另行配置。build.gradle.kts 中的 plugins {} 段默认从 Gradle Plugin Portal 中解析，我们要做的就是修改它的解析仓库地址。\n修改 settings.gradle.kts 文件\npluginManagement { repositories { maven(url = \u0026#34;https://maven.aliyun.com/repository/gradle-plugin\u0026#34;) gradlePluginPortal() } } 这样，该项目的全部依赖就都会走阿里云的 Maven 镜像仓库了。\n全局修改仓库地址 上面的内容只是修改了单个项目的仓库地址，这样如果每个项目都一个个修改的话就太麻烦了。那么有没有全局修改的办法呢？\n答案当然是有的，那就是修改 init.gradle.kts 初始化脚本。初始化脚本的位置为 `USER_HOME/.gradle/init.gradle.kts\u0026rsquo;。添加如下内容\nallprojects { repositories { maven { url = uri(\u0026#34;https://maven.aliyun.com/repository/public/\u0026#34;) } mavenLocal() mavenCentral() } } settingsEvaluated { pluginManagement { repositories { maven(url = \u0026#34;https://maven.aliyun.com/repository/gradle-plugin\u0026#34;) gradlePluginPortal() } } } 这样全部项目就都会走阿里云的镜像仓库了。\nGroovy 修改方式 另附 Groovy DSL 的修改方式。修改 init.gradle 脚本\nallprojects { repositories { maven { url \u0026#34;https://maven.aliyun.com/repository/public/\u0026#34; } mavenLocal() mavenCentral() } } settingsEvaluated { settings -\u0026gt; settings.pluginManagement { repositories { maven { url \u0026#34;https://maven.aliyun.com/repository/gradle-plugin\u0026#34; } gradlePluginPortal() } } } 参考链接：\nDeclaring repositories Using Gradle Plugins ","permalink":"http://localhost:1313/gradle-aliyun-maven/","summary":"\u003cp\u003e本文主要介绍了如何在 Kotlin 的 Gradle 项目中使用阿里云的 Maven 仓库加速。\u003c/p\u003e","title":"在 Gradle 项目中使用阿里云 Maven 仓库"},{"content":"本文主要介绍了如何解决前后端分离项目（前端：React + Vite，后端 Kotlin + Spring Security）的跨域问题。\n问题分析 前端的 Vite 运行在 http://localhost:5173，而后端的 Spring Boot 运行在 http://localhost:8080，端口号不同就带来了跨域（Cross-Origin）的问题。在默认情况下服务器不接受跨域的请求，这样请求就失败了。要解决这个问题有两种方法，分别是修改后端使其接受跨域请求，以及修改前端通过反向代理的方式直接消除跨域。下面分别介绍。\n修改后端 如果修改后端，那就是要使服务器接受跨域请求。如果没有使用 Spring Security 的话，直接在 Controller 上添加 @CrossOrgin 注解就可以了。但是 Spring Security 默认禁用了 CORS（Cross-origin resource sharing，跨域资源共享），那就还需要打开 CORS。\n在 SecurityConfig 文件里添加\n@Bean fun filterChain(http: HttpSecurity): SecurityFilterChain { http { /* *** */ cors { } } } 这样就启用了 CORS。但是，这样还需要我们在每一个 Controller 文件中添加 @CrossOrigin 注解，还是比较麻烦。更好的办法是直接全局修改响应头部。还是修改 SecurityConfig 文件\n@Bean fun filterChain(http: HttpSecurity): SecurityFilterChain { http { /* *** */ cors { } } } @Bean fun corsConfigurationSource(): CorsConfigurationSource { val source = UrlBasedCorsConfigurationSource() val configuration = CorsConfiguration() configuration.addAllowedOrigin(\u0026#34;http://127.0.0.1:5173\u0026#34;) configuration.allowCredentials = true configuration.addAllowedMethod(\u0026#34;*\u0026#34;) configuration.addAllowedHeader(\u0026#34;*\u0026#34;) configuration.addExposedHeader(\u0026#34;*\u0026#34;) source.registerCorsConfiguration(\u0026#34;/**\u0026#34;, configuration) return source } 注意，当 allowCredentials 设置为 true 时，allowedOrigin 不能设置为 * ，需要设置为具体的地址。这样，就可以正常接收前端的请求了。\n修改前端 当然，解决问题的最好办法就是直接消除跨域问题，而 Vite 正好提供了非常便利的解决方案。\n修改 vite.config.ts 文件\nexport default defineConfig({ plugins: [react()], server: { proxy: { \u0026#34;/api\u0026#34;: { target: \u0026#34;http://localhost:8080\u0026#34;, changeOrigin: true, rewrite: (path) =\u0026gt; path.replace(/^\\/api/, \u0026#34;\u0026#34;), }, }, }, }); Vite 服务器会架设代理，将 localhost:5173/api 的请求反向代理到 localhost:8080，这样 ip 和端口都一致，就不存在跨域的问题了。当然，这时请求的地址也要从 localhost:8080 修改到 /api 了。\n参考链接：\nVite 官方文档 ","permalink":"http://localhost:1313/vite-spring-cross-origin/","summary":"\u003cp\u003e本文主要介绍了如何解决前后端分离项目（前端：React + Vite，后端 Kotlin + Spring Security）的跨域问题。\u003c/p\u003e","title":"解决前端 Vite 和后端 Spring 跨域问题"},{"content":" If you don\u0026rsquo;t already know, camply is an open-source Python project that I created a little while ago that helps people to find and snag last minute cancellations at campgrounds all around the USA.\nI got the idea for camply when my partner and I took a road trip last summer. When we started planning campgrounds to stay at inside of National Parks during our trip, we quickly discovered that campsites at busy destinations like Yellowstone and Glacier are a hot commodity and totally booked out. After playing around in Chrome Developer tools on https://recreation.gov I realized that the APIs powering these websites can be used to proactively search for new availabilities to open up.\nBasically, camply works like this:\nInstall camply. pip install camply You get the ID numbers of your favorite, popular campground / recreation area using https://recreation.gov (you can do this with the camply CLI too, try camply --help on your commandline).\nYou use the camply CLI to search for a reservation to open up. This is pretty common on recreation.gov since their cancellation policy is generous and cheap. Check out the below command to search for campsites on weekends at Yosemite National Park (a rare find for certain coveted campgrounds).\ncamply campsites \\ --rec-area 2991 \\ --start-date 2022-06-01 \\ --end-date 2022-06-30 \\ --weekends \\ --continuous \\ --notifications pushover \\ --notify-first-try camply runs a Python process that searches for new cancellations and sends you a push notification on your phone once something becomes available.\nYou click the link on the notification and scramble to book the campsite before anybody else does.\nBoom! You\u0026rsquo;ve just booked yourself a hard to find campsite. That\u0026rsquo;s basically it. camply supports different notifications through email, Telegram, Pushover, and more. It also works at campgrounds in Yellowstone National Park that don\u0026rsquo;t use recreation.gov.\ncamply been one of my favorite side projects to work on and the major part of that enjoyment is because people out there are actually using it to find spots (almost 200 Stargazers on GitHub as of writing this 😍). As camply has been getting more popular the feature requests have begun to come in. Where I don\u0026rsquo;t have time to work on those features, camply could use some architecture simplification to empower more open source contributors to develop them instead.\nAs these new projects start to pile up, I\u0026rsquo;m beginning to ask myself: \u0026ldquo;does camply need a large overhaul and refactor to best support this?\u0026rdquo; If so, what\u0026rsquo;s the best way to do that and what functionality is the most important? My end goal is a camply version 1.0.0 but for now I\u0026rsquo;m trying to understand what to prioritize and how to make camply the best possible Python application it can be (see below for Feature Ideas and Tech Debt).\nIf you have any feature suggestions, thoughts, architecture recommendations, or interest in contributing to camply please let me know. Getting to connect with open source contributors has been the best part of building this and has made me a better developer in the process (the camping has been great too 🏕).\n\u0026ndash; jf\nP.S. If you\u0026rsquo;re interested in working on a spin-off of camply that finds and reserves last minute golfing tee times at golf courses around the world (including all the public Golf courses here in Denver, CO), let\u0026rsquo;s chat. I\u0026rsquo;ve got a Proof of Concept project that requires front end Python skills and I\u0026rsquo;m looking for partners to work with on it.\ndef reintroduce_myself(name: str) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34; Go away for awhile before posting again \u0026#34;\u0026#34;\u0026#34; intro = (f\u0026#34;Hey everyone, I\u0026#39;m {name}. \u0026#34; \u0026#34;I hope to have some more to say soon.\u0026#34;) print(intro) return intro if __name__ == \u0026#34;__main__\u0026#34;: reintroduce_myself(name=\u0026#34;juftin\u0026#34;) Camply Feature Ideas and Tech Debt Support multiple, simultaneous searches in the same process #77 and #76 This idea has been brought up a couple times. My current solution is to use Docker Compose to run multiple camply docker containers in the background. Search for campsites based on attributes #63 and #75 This one is a no-brainer. People want to search for campsites that can fit their RV (or whatever equipment they might have). camply needs to be able to filter results based on a campsite\u0026rsquo;s attributes and allowed equipment. Simplify adding new campsite providers #67 and #40 There have been a couple of requests for adding new Campsite providers (outside of Recreation.gov and Yellowstone). There is currently is an established pattern, including AbstractBaseClasses, to implement a new Campsite Booking Provider - but it\u0026rsquo;s admittedly clunky and not super intuitive for new contributors. Search for Wilderness Permits #22 This would be a tough, yet powerful feature to implement - it uses completely different endpoints and logic from regular campgrounds Search for specific campsites inside of campgrounds #51 Done! This was a simple, but rewarding feature to implement. People can now search for their favorite campsites in their local campground Persisted data stores (like a SQLite database) to store data between searches Currently, each new camply search stores all of its data in-memory. Persisting data between searches could enable more powerful searching Webserver UI This might be fun to build if camply is to ever become useful to a non-technical audience. Being able to configure searches via a WebUI would be very useful Managed Online Service for Hosted Searches I\u0026rsquo;m not sure if this is feasible. I\u0026rsquo;m not interested in making money with camply, but I\u0026rsquo;m also not interested in losing money. Hosting people\u0026rsquo;s searches on a webiste would be great, but possibly costly and require more time involved than I have to provide. ","permalink":"http://localhost:1313/manual/latex/2022-05-03-lets-talk-about-camply/","summary":"If you don\u0026rsquo;t already know, camply is an open-source Python project that I created a little while ago that helps people to find and snag last minute cancellations at campgrounds all around the USA.\nI got the idea for camply when my partner and I took a road trip last summer. When we started planning campgrounds to stay at inside of National Parks during our trip, we quickly discovered that campsites at busy destinations like Yellowstone and Glacier are a hot commodity and totally booked out.","title":"Let's talk about camply"},{"content":"本文介绍了如何在 Linux 下保存 Git 的用户凭据。\n在 Linux 的命令行中使用 Git 来推送提交的时候，默认并不会记住我们的用户凭据。我们每次推送的时候都需要手动输入账号和密码，这样就非常的麻烦。\n如果想要让 Git 记住我们的用户凭据也很简单，只需要设置\ngit config --global credential.helper store 这样当我们下次输入密码时，用户凭据就会被保存在 ~/.git-credentials 中，以后就不需要再手动输入了。\n","permalink":"http://localhost:1313/git-save-credential/","summary":"\u003cp\u003e本文介绍了如何在 Linux 下保存 Git 的用户凭据。\u003c/p\u003e","title":"Git 保存用户凭据"},{"content":"本文主要介绍了 Git commit 信息的一些规范。\ncommit 信息格式 每次提交，Commit message 都包括三个部分：Header，Body 和 Footer。\n\u0026lt;type\u0026gt;(\u0026lt;scope\u0026gt;): \u0026lt;subject\u0026gt; // 空一行 \u0026lt;body\u0026gt; // 空一行 \u0026lt;footer\u0026gt; 其中，Header 是必需的，Body 和 Footer 可以省略。\n不管是哪一个部分，任何一行都不得超过 72 个字符（或 100 个字符）。这是为了避免自动换行影响美观。\nHeader Header 部分只有一行，包括三个字段：type（必需）、scope（可选）和 subject（必需）。\ntype 用于说明 git commit 的类别，只允许使用下面的标识。\nfeat：新功能（feature）。 fix/to：修复 bug，可以是 QA 发现的 BUG，也可以是研发自己发现的 BUG。 fix：产生 diff 并自动修复此问题。适合于一次提交直接修复问题。 to：只产生 diff 不自动修复此问题。适合于多次提交。最终修复问题提交时使用 fix。 docs：文档（documentation）。 style：格式（不影响代码运行的变动）。 refactor：重构（即不是新增功能，也不是修改 bug 的代码变动）。 perf：优化相关，比如提升性能、体验。 test：增加测试。 chore：构建过程或辅助工具的变动。 revert：回滚到上一个版本。 merge：代码合并。 sync：同步主线或分支的 Bug。 scope scope 用于说明 commit 影响的范围，比如数据层、控制层、视图层等等，视项目不同而不同。\nsubject subject 是 commit 目的的简短描述，不超过 50 个字符。\n以动词开头，使用第一人称现在时，比如 change，而不是 changed 或 changes 第一个字母小写 结尾不加句号或其他标点符号 样例 fix(DAO): 用户查询缺少username属性 feat(Controller): 用户查询接口开发 Body Body 部分是对本次 commit 的详细描述，可以分成多行。下面是一个范例。\nMore detailed explanatory text, if necessary. Wrap it to about 72 characters or so. Further paragraphs come after blank lines. - Bullet points are okay, too - Use a hanging indent 使用第一人称现在时，比如使用 change 而不是 changed 或 changes。 应该说明代码变动的动机，以及与以前行为的对比。 Footer Footer 部分只用于两种情况。\n不兼容变动 如果当前代码与上一个版本不兼容，则 Footer 部分以 BREAKING CHANGE 开头，后面是对变动的描述、以及变动理由和迁移方法。\nBREAKING CHANGE: isolate scope bindings definition has changed. To migrate the code follow the example below: Before: scope: { myAttr: \u0026#39;attribute\u0026#39;, } After: scope: { myAttr: \u0026#39;@\u0026#39;, } The removed `inject` wasn\u0026#39;t generaly useful for directives so there should be no code using it. 关闭 Issue 如果当前 commit 针对某个 issue，那么可以在 Footer 部分关闭这个 issue 。\nCloses #234 也可以一次关闭多个 issue 。\nCloses #123, #245, #992 参考链接：\nCommit message 和 Change log 编写指南 - 阮一峰的网络日志 ","permalink":"http://localhost:1313/git-commit-specification/","summary":"\u003cp\u003e本文主要介绍了 Git commit 信息的一些规范。\u003c/p\u003e","title":"Git commit 信息规范"},{"content":"Clash for Windows（下简称 CFW）是一个常用的跨平台的代理软件。其 TUN 模式就类似于 VPN，通过创建一个虚拟网卡的方式来对流量实现更为彻底的代理。对于不遵循系统代理的软件，TUN 模式可以接管其流量并交由 CFW 处理。\nWindows 系统中启用 TUN 模式 启动 TUN 模式需要进行如下操作：\n点击 General 中 Service Mode 右边 Manage，在打开窗口中安装服务模式，安装完成应用会自动重启，Service Mode 右边地球图标变为绿色即安装成功。 点击 General 中 TUN Mode 右边开关启动 TUN 模式。 使用 system 作为 TUN stack TUN 模式默认的 stack 为 gVisor，除此之外还有一个 system stack。system 使用内核的 TCP/IP 协议栈，在理论上行为与系统的 TCP/IP 最接近，兼容性最强。\n但是需要将 clash core 从防火墙中放行才能正常工作。\n设置 - 更新和安全 - Windows 安全中心 - 防火墙和网络保护 - 允许应用通过防火墙 - clash-win64.exe - 专用/公用 都放行。\nAllow LAN 安装 Service Mode 后 Allow LAN 功能可能会失效，如需要局域网连接功能谨慎开启。\n参考链接：\nTUN 防火墙 Allow LAN ","permalink":"http://localhost:1313/cfw-tun-system/","summary":"\u003cp\u003eClash for Windows（下简称 CFW）是一个常用的跨平台的代理软件。其 TUN 模式就类似于 VPN，通过创建一个虚拟网卡的方式来对流量实现更为彻底的代理。对于不遵循系统代理的软件，TUN 模式可以接管其流量并交由 CFW 处理。\u003c/p\u003e","title":"Clash for Windows 启用 TUN 模式"},{"content":"本文主要介绍了 Hugo 中的短代码 Shortcodes。\n什么是短代码 我们采用 Markdown 来写博客是因为它的内容格式简单，但有时 Markdown 也不尽如人意。这时候，内容作者就被迫添加原始 HTML 代码到 Markdown 内容中去。这是与 Markdown 语法的优美简洁相矛盾的，因此 Hugo 创建了短代码来规避这些限制。短代码是内容文件中的一个简单片段，Hugo 将使用预定义的模板来呈现它。\nHugo 的内置短代码 Hugo 附带了一组预定义的短代码，它们代表了非常常见的用法。提供这些短代码是为了方便作者并保持您的 Markdown 内容干净，比如 figure, gist, highlight, instagram 等。下面以 figure 为例来介绍。\nfigure 是 Markdown 中图像语法的扩展，可用的参数有：src, link, target, rel, alt, title, caption, class, height, width, attr 以及 attrlink。示例 figure 输入如下\n\\{\\{\u0026lt; figure src=\u0026#34;/media/spf13.jpg\u0026#34; title=\u0026#34;Steve Francia\u0026#34; \u0026gt;\\}\\} 它将被转化为如下的 html 代码\n\u0026lt;figure\u0026gt; \u0026lt;img src=\u0026#34;/media/spf13.jpg\u0026#34; /\u0026gt; \u0026lt;figcaption\u0026gt; \u0026lt;h4\u0026gt;Steve Francia\u0026lt;/h4\u0026gt; \u0026lt;/figcaption\u0026gt; \u0026lt;/figure\u0026gt; 自定义短代码 除了使用 Hugo 自带的短代码外，我们还可以自定义短代码。\n要自定义短代码，我们需要在 /layouts/shortcodes/ 目录下创建短代码文件，文件名为 “shortcode.html”。在 shortcode 中，可以通过 .Get 方法来访问参数。\n要按名称访问参数，请使用 .Get 方法，后跟命名参数作为带引号的字符串：\n{{ .Get \u0026#34;class\u0026#34; }} 要按位置访问参数，请使用 .Get 后跟数字位置，记住位置参数是零索引的：\n{{ .Get 0 }} {{ .Get 1 }} 当输出取决于设置的参数时可以使用 with:\n{{ with .Get \u0026#34;class\u0026#34; }} class=\u0026#34;{{ . }}\u0026#34;{{ end }} 当条件取决于任一值或两者时，.Get 也可用于检查是否提供了参数：\n{{ if or (.Get \u0026#34;title\u0026#34;) (.Get \u0026#34;alt\u0026#34;) }} alt=\u0026#34;{{ with .Get \u0026#34;alt\u0026#34; }}{{ . }}{{ else }}{{ .Get \u0026#34;title\u0026#34; }}{{ end }}\u0026#34;{{ end }} 下面以插入图片的短代码 img.html 为例来介绍。\n\u0026lt;!-- image --\u0026gt; \u0026lt;figure class=\u0026#34;align-center\u0026#34;\u0026gt; \u0026lt;img src=\u0026#34;assets/{{ .Get `src` }}#center\u0026#34; width=\u0026#34;{{- if .Get `width` -}} {{ .Get `width` }}{{ else }} 60% {{- end -}}\u0026#34; /\u0026gt; \u0026lt;figcaption\u0026gt;{{ with (.Get \u0026#34;title\u0026#34;) -}} {{ . }} {{- end -}}\u0026lt;/figcaption\u0026gt; \u0026lt;/figure\u0026gt; 上述代码实现了图片居中，自定义图片宽度（默认为 60%）及显示图注。\n之后，我们就可以在 Markdown 文件中来使用该短代码\n\\{\\{\u0026lt; img src=\u0026#34;/media/spf13.jpg\u0026#34; width=\u0026#34;80%\u0026#34; title=\u0026#34;Steve Francia\u0026#34; \u0026gt;}} 参考链接：\nShortcodes Create Your Own Shortcodes ","permalink":"http://localhost:1313/hugo-shortcodes/","summary":"\u003cp\u003e本文主要介绍了 Hugo 中的短代码 Shortcodes。\u003c/p\u003e","title":"在 Hugo 中使用短代码"},{"content":" When I was setting up my portfolio site I realized that it also has some pretty nifty blogging capabilities too. Well\u0026hellip; I guess I have a blog now.\nI\u0026rsquo;m not typically one to channel my energy through writing so I don\u0026rsquo;t expect to be extremely active on here but it\u0026rsquo;s nice to have a venue where I can record my thoughts from time to time.\nIn the meantime I\u0026rsquo;ll begin to work on putting together some more content to showcase some of my open source work.\nThanks for being here\n\u0026ndash; jf\ndef introduce_myself(name: str) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34; Say Hi to everyone \u0026#34;\u0026#34;\u0026#34; intro = (f\u0026#34;Hey everyone, I\u0026#39;m {name}. \u0026#34; \u0026#34;It\u0026#39;s really nice to be here\u0026#34;) print(intro) return intro if __name__ == \u0026#34;__main__\u0026#34;: introduce_myself(name=\u0026#34;juftin\u0026#34;) ","permalink":"http://localhost:1313/manual/latex/2022-02-08-welcome/","summary":"When I was setting up my portfolio site I realized that it also has some pretty nifty blogging capabilities too. Well\u0026hellip; I guess I have a blog now.\nI\u0026rsquo;m not typically one to channel my energy through writing so I don\u0026rsquo;t expect to be extremely active on here but it\u0026rsquo;s nice to have a venue where I can record my thoughts from time to time.\nIn the meantime I\u0026rsquo;ll begin to work on putting together some more content to showcase some of my open source work.","title":"I guess I have a blog now"},{"content":"本文主要介绍了在数据库设计中常见的三大范式及 BC 范式。\n首先要明白”范式（NF）”是什么意思。按照教材中的定义，范式是“符合某一种级别的关系模式的集合，表示一个关系内部各属性之间的联系的合理化程度”。很晦涩吧？实际上你可以把它粗略地理解为一张数据表的表结构所符合的某种设计标准的级别。就像家里装修买建材，最环保的是 E0 级，其次是 E1 级，还有 E2 级等等。数据库范式也分为 1NF，2NF，3NF，BCNF，4NF，5NF。一般在我们设计关系型数据库的时候，最多考虑到 BCNF 就够。符合高一级范式的设计，必定符合低一级范式，例如符合 2NF 的关系模式，必定符合 1NF。\n接下来就对每一级范式进行一下解释。\n第一范式（1NF） 符合 1NF 的关系（你可以理解为数据表。“关系模式”和“关系”的区别，类似于面向对象程序设计中”类“与”对象“的区别。”关系“是”关系模式“的一个实例，你可以把”关系”理解为一张带数据的表，而“关系模式”是这张数据表的表结构。1NF 的定义为：符合 1NF 的关系中的每个属性都不可再分。 表 1 所示的情况，就不符合 1NF 的要求。\n表1 实际上，1NF 是所有关系型数据库的最基本要求 ，你在关系型数据库管理系统（RDBMS），例如 SQL Server，Oracle，MySQL 中创建数据表的时候，如果数据表的设计不符合这个最基本的要求，那么操作一定是不能成功的。也就是说，只要在 RDBMS 中已经存在的数据表，一定是符合 1NF 的。如果我们要在 RDBMS 中表现表中的数据，就得设计为表 2 的形式：\n表2 但是仅仅符合 1NF 的设计，仍然会存在数据冗余过大，插入异常，删除异常，修改异常的问题，例如对于表 3 中的设计：\n表3 每一名学生的学号、姓名、系名、系主任这些数据重复多次。每个系与对应的系主任的数据也重复多次——数据冗余过大\n假如学校新建了一个系，但是暂时还没有招收任何学生（比如 3 月份就新建了，但要等到 8 月份才招生），那么是无法将系名与系主任的数据单独地添加到数据表中去的 （注１）——插入异常\n注１：根据三种关系完整性约束中实体完整性的要求，关系中的码（注２）所包含的任意一个属性都不能为空，所有属性的组合也不能重复。为了满足此要求，图中的表，只能将学号与课名的组合作为码，否则就无法唯一地区分每一条记录。\n注２：码：关系中的某个属性或者某几个属性的组合，用于区分每个元组（可以把“元组”理解为一张表中的每条记录，也就是每一行）。\n假如将某个系中所有学生相关的记录都删除，那么所有系与系主任的数据也就随之消失了（一个系所有学生都没有了，并不表示这个系就没有了）——删除异常\n假如李小明转系到法律系，那么为了保证数据库中数据的一致性，需要修改三条记录中系与系主任的数据。——修改异常\n正因为仅符合 1NF 的数据库设计存在着这样那样的问题，我们需要提高设计标准，去掉导致上述四种问题的因素，使其符合更高一级的范式（2NF），这就是所谓的“规范化”。\n第二范式（2NF） 在关系理论中的严格定义我这里就不多介绍了（因为涉及到的铺垫比较多），只需要了解 2NF 对 1NF 进行了哪些改进即可。其改进是，2NF 在 1NF 的基础之上，消除了非主属性对于码的部分函数依赖。 接下来对这句话中涉及到的四个概念——“函数依赖” 、“码” 、“非主属性” 、与 “部分函数依赖” 进行一下解释。\n1. 函数依赖 我们可以这么理解（但并不是特别严格的定义）：若在一张表中，在属性（或属性组）X 的值确定的情况下，必定能确定属性 Y 的值，那么就可以说 Y 函数依赖于 X，写作 X → Y。 也就是说，在数据表中，不存在任意两条记录，它们在 X 属性（或属性组）上的值相同，而在 Y 属性上的值不同。这也就是“函数依赖”名字的由来，类似于函数关系 y = f(x)，在 x 的值确定的情况下，y 的值一定是确定的。\n例如，对于表 3 中的数据，找不到任何一条记录，它们的学号相同而对应的姓名不同。所以我们可以说 姓名函数依赖于学号 ，写作 学号 → 姓名。但是反过来，因为可能出现同名的学生，所以有可能不同的两条学生记录，它们在姓名上的值相同，但对应的学号不同，所以我们不能说学号函数依赖于姓名。表中其他的函数依赖关系还有如：\n系名 → 系主任 学号 → 系主任 （学号，课名） → 分数 但以下函数依赖关系则不成立：\n学号 → 课名 学号 → 分数 课名 → 系主任 （学号，课名） → 姓名 从“函数依赖”这个概念展开，还会有三个概念：\n2. 完全函数依赖 在一张表中，若 X → Y，且对于 X 的任何一个真子集（假如属性组 X 包含超过一个属性的话），X\u0026rsquo; → Y 不成立，那么我们称 Y 对于 X 完全函数依赖，记作 X F→ Y。\n图1 例如：\n学号 F→ 姓名 （学号，课名） F→ 分数 （注：因为同一个的学号对应的分数不确定，同一个课名对应的分数也不确定） 3. 部分函数依赖 假如 Y 函数依赖于 X，但同时 Y 并不完全函数依赖于 X，那么我们就称 Y 部分函数依赖于 X，记作 X P→ Y，如图 2。\n图2 例如：\n（学号，课名） P→ 姓名 4. 传递函数依赖 假如 Y 不包含于 X，且 X 不函数依赖于 Y，并且有 Z 函数依赖于 Y，Y 函数依赖于 X，那么我们就称 Z 传递函数依赖于 X ，记作 X T→ Z，如图 3。\n图3 5. 码 设 K 为某表中的一个属性或属性组，若除 K 之外的所有属性都完全函数依赖于 K，那么我们称 K 为 候选码，简称为 码。在实际中我们通常可以理解为：假如当 K 确定的情况下，该表除 K 之外的所有属性的值也就随之确定，那么 K 就是码。一张表中可以有超过一个码。（实际应用中为了方便，通常选择其中的一个码作为 主码）\n例如：对于表 3，（学号、课名） 这个属性组就是码。该表中有且仅有这一个码。（假设所有课没有重名的情况）\n6. 非主属性 包含在任何一个码中的属性成为主属性。\n例如：对于表 3，主属性就有两个，学号 与 课名。\n终于可以回过来看 2NF 了。首先，我们需要判断，表 3 是否符合 2NF 的要求？根据 2NF 的定义，判断的依据实际上就是看数据表中 是否存在非主属性对于码的部分函数依赖。若存在，则数据表最高只符合 1NF 的要求，若不存在，则符合 2NF 的要求。判断的方法是：\n第一步：找出数据表中所有的 码。 第二步：根据第一步所得到的码，找出所有的 主属性。 第三步：数据表中，除去所有的主属性，剩下的就都是 非主属性 了。 第四步：查看是否存在非主属性对码的 部分函数依赖。\n对于表 3，根据前面所说的四步，我们可以这么做：\n第一步：\n查看所有每一单个属性，当它的值确定了，是否剩下的所有属性值都能确定。 查看所有包含有两个属性的属性组，当它的值确定了，是否剩下的所有属性值都能确定。 …… 查看所有包含了六个属性，也就是所有属性的属性组，当它的值确定了，是否剩下的所有属性值都能确定。 看起来很麻烦是吧，但是这里有一个诀窍，就是假如 A 是码，那么所有包含了 A 的属性组，如（A，B）、（A，C）、（A，B，C）等等，都不是码了（因为作为码的要求里有一个“完全 函数依赖”）。\n图 4 表示了表中所有的函数依赖关系：\n图4 这一步完成以后，可以得到，表 3 的码只有一个，就是 （学号、课名）。\n第二步：主属性有两个：学号 与 课名\n第三步：非主属性有四个：姓名、系名、系主任、分数\n第四步：\n对于 （学号，课名） → 姓名，有 学号 → 姓名，存在非主属性 姓名 对码 （学号，课名） 的部分函数依赖。\n对于 （学号，课名） → 系名，有 学号 → 系名，存在非主属性 系名 对码 （学号，课名） 的部分函数依赖。\n对于 （学号，课名） → 系主任，有 学号 → 系主任，存在非主属性 系主任 对码 （学号，课名） 的部分函数依赖。\n所以表 3 存在非主属性对于码的部分函数依赖，最高只符合 1NF 的要求，不符合 2NF 的要求。\n为了让表 3 符合 2NF 的要求，我们必须消除这些部分函数依赖，只有一个办法，就是将大数据表拆分成两个或者更多个更小的数据表，在拆分的过程中，要达到更高一级范式的要求，这个过程叫做”模式分解“。模式分解的方法不是唯一的，以下是其中一种方法：\n选课（学号，课名，分数） 学生（学号，姓名，系名，系主任） 我们先来判断以下，选课 表与 学生 表，是否符合了 2NF 的要求？\n对于 选课 表，其码是 （学号，课名），主属性是 学号 和 课名 ，非主属性是 分数，学号 确定，并不能唯一确定 分数，课名 确定，也不能唯一确定 分数，所以不存在非主属性 分数 对于码 （学号，课名） 的部分函数依赖，所以此表符合 2NF 的要求。\n对于学生表，其码是 学号，主属性是 学号，非主属性是 姓名、系名和系主任，因为码只有一个属性，所以不可能存在非主属性对于码 的部分函数依赖，所以此表符合 2NF 的要求。\n图 5 表示了模式分解以后的新的函数依赖关系\n图5 表 4 表示了模式分解以后新的数据\n表4 现在我们来看一下，进行同样的操作，是否还存在着之前的那些问题？\n李小明转系到法律系 只需要修改一次李小明对应的系的值即可。——有改进 数据冗余是否减少了？ 学生的姓名、系名与系主任，不再像之前一样重复那么多次了。——有改进 删除某个系中所有的学生记录 该系的信息仍然全部丢失。——无改进 插入一个尚无学生的新系的信息 因为学生表的码是学号，不能为空，所以此操作不被允许。——无改进 所以说，仅仅符合 2NF 的要求，很多情况下还是不够的，而出现问题的原因，在于仍然存在非主属性 系主任 对于码 学号 的传递函数依赖。为了能进一步解决这些问题，我们还需要将符合 2NF 要求的数据表改进为符合 3NF 的要求。\n第三范式（3NF） 3NF 在 2NF 的基础之上，消除了非主属性对于码的传递函数依赖。也就是说， 如果存在非主属性对于码的传递函数依赖，则不符合 3NF 的要求。\n接下来我们看看表 4 中的设计，是否符合 3NF 的要求。\n对于 选课 表，主码为 （学号，课名），主属性为 学号 和 课名，非主属性只有一个，为 分数 ，不可能存在传递函数依赖，所以 选课 表的设计，符合 3NF 的要求。\n对于 学生 表，主码为 学号 、，主属性为 学号，非主属性为 姓名、系名和系主任。因为 学号 → 系名，同时 系名 → 系主任，所以存在非主属性 系主任 对于码 学号 的传递函数依赖，所以 学生 表的设计，不符合 3NF 的要求。\n为了让数据表设计达到 3NF，我们必须进一步进行模式分解为以下形式：\n选课（学号，课名，分数） 学生（学号，姓名，系名） 系（系名，系主任） 对于 选课 表，符合 3NF 的要求，之前已经分析过了。\n对于 学生 表，码为 学号，主属性为 学号，非主属性为 系名，不可能存在非主属性对于码的传递函数依赖，所以符合 3NF 的要求。\n对于 系 表，码为 系名，主属性为 系名，非主属性为 系主任，不可能存在非主属性对于码的传递函数依赖（至少要有三个属性才可能存在传递函数依赖关系），所以符合 3NF 的要求。\n新的函数依赖关系如图 6\n图6 新的数据表如表 5\n表5 现在我们来看一下，进行同样的操作，是否还存在着之前的那些问题？\n删除某个系中所有的学生记录 该系的信息不会丢失。——有改进 插入一个尚无学生的新系的信息。 因为系表与学生表目前是独立的两张表，所以不影响。——有改进 数据冗余更加少了。——有改进 结论\n由此可见，符合 3NF 要求的数据库设计，基本 上解决了数据冗余过大，插入异常，修改异常，删除异常的问题。当然，在实际中，往往为了性能上或者应对扩展的需要，经常做到 2NF 或者 1NF，但是作为数据库设计人员，至少应该知道，3NF 的要求是怎样的。\nBoyce-Codd 范式（BCNF） 要了解 BCNF，那么先看这样一个问题：\n若：\n某公司有若干个仓库； 每个仓库只能有一名管理员，一名管理员只能在一个仓库中工作； 一个仓库中可以存放多种物品，一种物品也可以存放在不同的仓库中。每种物品在每个仓库中都有对应的数量。 那么关系模式 仓库（仓库名，管理员，物品名，数量） 属于哪一级范式？\n答：已知函数依赖集：\n仓库名 → 管理员 管理员 → 仓库名 （仓库名，物品名）→ 数量 码：（管理员，物品名），（仓库名，物品名）\n主属性：仓库名、管理员、物品名\n非主属性：数量\n∵ 不存在非主属性对码的部分函数依赖和传递函数依赖。\n∴ 此关系模式属于 3NF。\n基于此关系模式的关系（具体的数据）可能如表 6 所示：\n表6 好，既然此关系模式已经属于了 3NF，那么这个关系模式是否存在问题呢？我们来看以下几种操作：\n先新增加一个仓库，但尚未存放任何物品，是否可以为该仓库指派管理员？——不可以，因为物品名也是主属性，根据实体完整性的要求，主属性不能为空。\n某仓库被清空后，需要删除所有与这个仓库相关的物品存放记录，会带来什么问题？——仓库本身与管理员的信息也被随之删除了。\n如果某仓库更换了管理员，会带来什么问题？——这个仓库有几条物品存放记录，就要修改多少次管理员信息。\n从这里我们可以得出结论，在某些特殊情况下，即使关系模式符合 3NF 的要求，仍然存在着插入异常，修改异常与删除异常的问题，仍然不是 ”好“ 的设计。\n造成此问题的原因：存在着 主属性 对于 码 的部分函数依赖与传递函数依赖。（在此例中就是存在主属性 仓库名 对于码 （管理员，物品名） 的部分函数依赖。\n解决办法就是要在 3NF 的基础上消除 主属性 对于 码 的部分与传递函数依赖。\n仓库（仓库名，管理员） 库存（仓库名，物品名，数量） 这样，之前的插入异常，修改异常与删除异常的问题就被解决了。\n以上就是关于 BCNF 的解释。\n参考链接：\n如何理解关系型数据库的常见设计范式？ - 刘慰的回答 - 知乎 ","permalink":"http://localhost:1313/database-normal-forms/","summary":"\u003cp\u003e本文主要介绍了在数据库设计中常见的三大范式及 BC 范式。\u003c/p\u003e","title":"数据库设计常见范式介绍"},{"content":"本文主要介绍了正则表达式的一些基本用法。\n正则表达式是一种查找以及字符串替换操作。正则表达式在文本编辑器中广泛使用，比如正则表达式被用于：\n检查文本中是否含有指定的特征词 找出文中匹配特征词的位置 从文本中提取信息，比如：字符串的子串 修改文本 与文本编辑器相似，几乎所有的高级编程语言都支持正则表达式。在这样的语境下，\u0026ldquo;文本\u0026quot;也就是一个字符串，可以执行的操作都是类似的。一些编程语言（比如 Perl，JavaScript）会检查正则表达式的语法。\n正则表达式是什么？ 正则表达式只是一个字符串。没有长度限制，但是，这样的正则表达式长度往往较短。如下所示是一些正则表达式的例子：\nI had a \\S+ day today [A-Za-z0-9\\-_]{3,16} \\d\\d\\d\\d-\\d\\d-\\d\\d v(\\d+)(\\.\\d+)\\* TotalMessages=\u0026quot;(.\\*?)\u0026quot; \u0026lt;[^\u0026lt;\u0026gt;]\u0026gt; 这些字符串实际上都是微型计算机程序。正则表达式的语法，实际上是一种轻量级、简洁、适用于特定领域的编程语言。记住这一点，那么你就很容易理解下面的事情：\n每一个正则表达式，都可以分解为一个指令序列，比如\u0026quot;先找到这样的字符，再找到那样的字符，再从中找到一个字符\u0026hellip;\u0026rdquo; 每一个正则表达式都有输入（文本）和输出（匹配规则的输出，有时是修改后的文本） 正则表达式有可能出现语法错误——不是所有的字符串都是正则表达式 正则表达式语法很有个性，也可以说很恐怖 有时可以通过编译，使得正则表达式执行更快 在实现中，正则表达式还有其他的特点。本文将重点讨论正则表达式的核心语法，在几乎所有的正则表达式中都可以见到这些规则。 特别提示：正则表达式与文件通配语法无关，比如 \\*.xml\n正则表达式的基础语法 字符 正则表达式中包含了一系列的字符，这些字符只能匹配它们本身。有一些被称为\u0026quot;元字符\u0026quot;的特殊字符，可以匹配一些特殊规则。\n大部分的字符，包括所有的字母和数字字符，是普通字符。也就意味着，它们只能匹配它们自己，如下所示的正则表达式：\ncat\n意味着，只能匹配一个字符串，以\u0026quot;c\u0026quot;开头，然后是字符\u0026quot;a\u0026quot;，紧跟着是字符\u0026quot;t\u0026quot;的字符串。\n注意：不做特殊说明，正则表达式中是区分大小写的。但是，几乎所有正则表达式的实现，都会提供一个 Flag 用来控制是否区分大小写。\n点\u0026quot;.\u0026quot; 我们第一个要讲解的元字符是\u0026quot;.\u0026quot;。这个符号意味着可以匹配任意一个字符。如下所示的正则表达式：\nc.t\n意味着匹配\u0026quot;以 c 开头,之后是任意一个字符，紧跟着是字母 t\u0026quot;的字符串。\n在一段文本中，这样的正则表达式可以用来找出 cat, cot, czt 这样的字符串，甚至可以找出 c.t 这样的组合，但是不能找到 ct 或者是 coot 这样的字符串。\n使用反斜杠\u0026quot;\u0026quot;可以忽略元字符，使得元字符的功能与普通字符一样。所以，正则表达式\nc\\.t\n表示\u0026quot;找到字母 c,然后是一个句号(\u0026quot;.\u0026quot;)，紧跟着字母 t\u0026quot;\n反斜杠本身也是一个元字符，这意味着反斜杠本身也可以通过相似的方法变回到普通字符的用途。因此，正则表达式\nc\\\\t\n表示匹配\u0026quot;以字符 c 开头,然后是一个反斜杠，紧跟着是字母 t\u0026quot;的字符串。\n注意！在正则表达式的实现中，.是不能用于匹配换行符的。\u0026ldquo;换行符\u0026quot;的表示方法在不同实现中也不同。实际编程时，请参考相关文档。在本文中，我认为 . 是可以匹配任意字符的。实现环境通常会提供一个 Flag 标志位，来控制这一点。\n字符类 字符类是一组在方括号内的字符，表示可以匹配其中的任何一个字符。\n正则表达式 c[aeiou]t，表示可以匹配的字符串是\u0026quot;以 c 开头，接着是 aeiou 中的任何一个字符，最后以 t 结尾\u0026rdquo;。在文本的实际应用中，这样的正则表达式可以匹配：cat, cet, cit, cot, cut 五种字符串。 正则表达式 [0123456789] 表示匹配任意一个整数。 正则表达式 [a] 表示匹配单字符 a。 在字符类中，字符的重复和出现顺序并不重要。[dabaaabcc] 与 [abc] 是相同的\n重要提示：字符类中和字符类外的规则有时不同，一些字符在字符类中是元字符，在字符类外是普通字符。一些字符正好相反。还有一些字符在字符类中和字符类外都是元字符，这要视情况而定！\n比如，. 表示匹配任意一个字符，而 [.] 表示匹配一个全角句号。这不是一回事！\n字符类的范围 在字符集中，你可以通过使用短横线来表示匹配字母或数字的范围。\n[b-f] 与 [b,c,d,e,f] 相同，都是匹配一个字符\u0026quot;b\u0026quot;或\u0026quot;c\u0026quot;或\u0026quot;d\u0026quot;或\u0026quot;e\u0026quot;或\u0026quot;f\u0026quot; [A-Z] 与 [ABCDEFGHIJKLMNOPQRSTUVWXYZ] 相同，都是匹配任意一个大写字母。 [1-9] 与 [123456789] 相同，都是匹配任意一个非零数字。 字符类的反义 你可以在字符类的起始位放一个反义符。\n[^a] 表示匹配任何不是\u0026quot;a\u0026quot;的字符 [^a-za-z0-9] 表示匹配任何不是字母也不是数字的字符 [\\^abc] 匹配一个为\u0026quot;^\u0026ldquo;或者 a 或者 b 或者 c 的字符 [^\\^] 表示匹配任何不为\u0026rdquo;^\u0026ldquo;的字符 转义字符类 \\d 这个正则表达式与 [0-9] 作用相同，都是匹配任何一个数字。（要匹配 \\d,应该使用正则表达式 \\\\d）\n\\w 与 [0-9A-Za-z] 相同，都表示匹配一个数字或字母字符\n\\s 意味着匹配一个空字符（空格，制表符，回车或者换行）\n另外\n\\D 与 [^0-9] 相同，表示匹配一个非数字字符。\n\\W 与 [^0-9a-za-z] 相同，表示匹配一个非数字同时不是字母的字符。\n\\S 表示匹配一个非空字符。\n这些是你必须掌握的字符。你可能已经注意到了，一个全角句号\u0026rdquo;.\u0026ldquo;也是一个字符类，可以匹配任意一个字符。\n很多正则表达式的实现中，提供了更多的字符类，或者是标志位在 ASCII 码的基础上，扩展现有的字符类。\n特别提示：统一字符集中包含除了 0 至 9 之外的更多数字字符，同样的，也包含更多的空字符和字母字符。实际使用正则表达式时，请仔细查看相关文档。\n重复 在字符或字符集之后，你可以使用{ }大括号来表示重复\n正则表达式 a{1} 与 a 意思相同，都表示匹配字母 a a{3} 表示匹配字符串\u0026quot;aaa\u0026rdquo; a{0} 表示匹配空字符串。从这个正则表达式本身来看，它毫无意义。如果你对任何文本执行这样的正则表达式，你可以定位到搜索的起始位置，即使文本为空。 a\\{2\\} 表示匹配字符串\u0026quot;a{2}\u0026quot; 在字符类中，大括号没有特殊含义。[{}] 表示匹配一个左边的大括号，或者一个右边的大括号 注意：重复字符是没有记忆性的，比如 [abc]{2} 表示先匹配\u0026quot;a 或者 b 或者 c\u0026quot;，再匹配\u0026quot;a 或者 b 或者 c\u0026quot;，与匹配\u0026quot;aa 或者 ab 或者 ac 或者 ba 或者 bb 或者 bc 或者 ca 或者 cb 或者 cc\u0026quot;一样。[abc]{2} 并不能表示匹配\u0026quot;aa 或者 bb 或者 cc\u0026quot;\n指定重复次数范围 重复次数是可以指定范围的\nx{4,4} 与 x{4} 相同 colou{0,1}r 表示匹配 colour 或者 color a{3,5} 表示匹配 aaaaa 或者 aaaa 或者 aaa 注意这样的正则表达式会优先匹配最长字符串，比如输入 I had an aaaaawful day 会匹配单词 aaaaawful 中的 aaaaa，而不会匹配其中的 aaa。 重复次数是可以有范围的，但是有时候这样的方法也不能找到最佳答案。如果你的输入文本是 I had an aaawful daaaaay 那么在第一次匹配时，只能找到 aaawful，只有再次执行匹配时才能找到 daaaaay 中的 aaaaa.\n重复次数的范围可以是开区间\na{1，} 表示匹配一个或一个以上的连续字符 a。依然是匹配最长字符串。当找到第一个 a 之后，正则表达式会尝试匹配尽量多个的连续字母 a。 .{0,} 表示匹配任意内容。无论你输入的文本是什么，即使是一个空字符串，这个正则表达式都会成功匹配全文并返回结果。 关于重复的转义字符 ?与 {0,1} 相同，比如，colou?r 表示匹配 colour 或者 color\n* 与 {0,} 相同。比如 .* 表示匹配任意内容\n+ 与 {1，} 相同。比如 \\w+ 表示匹配一个词。其中\u0026quot;一个词\u0026quot;表示由一个或一个以上的字符组成的字符串，比如 _var 或者 AccountName1.\n这些是你必须知道的常用转义字符，除此之外还有:\n\\?\\*\\+ 表示匹配字符串\u0026quot;?*+\u0026quot; [?*+] 表示匹配一个问号，或者一个 * 号，或者一个加号 非贪婪匹配 正则表达式 \u0026quot;.\\*\u0026quot; 表示匹配双引号，之后是任意内容，之后再匹配一个双引号。注意，其中匹配任意内容也可以是双引号。通常情况下，这并不是很有用。通过在句尾加上一个问号，可以使得字符串重复不再匹配最长字符。\n\\d{4,5}? 表示匹配 \\d\\d\\d\\d 或者 \\d\\d\\d\\d\\d。也就是和 \\d{4} 一样 colou??r 与 colou{0,1}r 相同，表示找到 color 或者 colour。这与 colou?r 一样。 \u0026quot;.\\*?\u0026quot; 表示先匹配一个双引号，然后匹配最少的字符，然后是一个双引号，与上面两个例子不同，这很有用。 选择匹配 你可以使用|来分隔可以匹配的不同选择:\ncat|dog 表示匹配\u0026quot;cat\u0026quot;或者\u0026quot;dog\u0026quot; red|blue| 以及 red||blue 以及 |red|blue 都表示匹配 red 或者 blue 或者一个空字符串 a|b|c 与 [abc] 相同 cat|dog|\\| 表示匹配\u0026quot;cat\u0026quot;或者\u0026quot;dog\u0026quot;或者一个分隔符\u0026quot;|\u0026quot; [cat|dog] 表示匹配 a 或者 c 或者 d 或者 g 或者 o 或者 t 或者一个分隔符\u0026quot;|\u0026quot; 分组 你可以使用括号表示分组:\n通过使用 (Mon|Tues|Wednes|Thurs|Fri|Satur|Sun)day 匹配一周中的某一天 (\\w*)ility 与 \\w*ility 相同。都是匹配一个由\u0026quot;ility\u0026quot;结尾的单词。稍后我们会讲解，为何第一种方法更加有用。 \\(\\) 表示匹配一对括号。 [()] 表示匹配任意一个左括号或者一个右括号 单词分隔符 在单词和非单词之间有单词分隔符。记住，一个单词 \\w 是 [0-9A-Za-z_]，而非单词字符是 \\W(大写)，表示 [^0-9a-za-z_]。\n在文本的开头和结尾通常也有单词分隔符。\n在输入文本 it’s a cat 中，实际有八个单词分隔符。如果我们在 cat 之后在上一个空格，那就有九个单词分隔符。\n\\b 表示匹配一个单词分隔符 \\b\\w\\w\\w\\b 表示匹配一个三字母单词 a\\ba 表示匹配两个 a 中间有一个单词分隔符。这个正则表达式永远不会有匹配的字符，无论输入怎样的文本。 单词分隔符本身并不是字符。它们的宽度为 0。下列正则表达式的作用不同\n(\\bcat)\\b (\\bcat\\b) \\b(cat)\\b \\b(cat\\b) 换行符 一篇文本中可以有一行或多行，行与行之间由换行符分隔。\n注意，所有的文本都是以一行结束的，而不是以换行符结束。但是，任意一行都可能为空，包括最后一行。\n行的起始位置，是在换行符和下一行首字符之间的空间。考虑到单词分隔符，文本的起始位置也可以当做是首行位置。\n最后一行是最后一行的尾字符和换行符之间的空间。考虑到单词分隔符，文本的结束也可以认为是行的结束。\n那么新的格式表示如下:\n那么新的格式表示如下:\nStart-of-line, line, end-of-line Line break Start-of-line, line, end-of-line Line break … Line break Start-of-line, line, end-of-line 基于上述概念:\n^ 表示匹配行的开始位置 $ 表示匹配行的结束位置 ^\u0026amp; 表示一个空行 ^._\u0026amp; 表示匹配全文内容，因为行的开始符号也是一个字符，\u0026quot;.\u0026ldquo;会匹配这个符号。找到单独的一行，可以使用 ^._?$ \\^\\$ 表示匹配字符串\u0026rdquo;^$\u0026quot; [$] 表示匹配一个 $。但是，[^] 不是合法的正则表达式。记住在方括号中，字符有不同的特殊含义。要想在方括号内匹配 ^，必须用 [\\^] 与字符分隔符一样，换行符也不是字符。它们宽度为 0.如下所示的正则表达式作用不同：\n(^cat)$ (^cat$) ^(cat)$ ^(cat$) 文本分界 在很多的正则表达式实现中，将 ^ 和 $ 作为文本的开始符号和结束符号。\n还有一些实现中，用 \\A 和 \\z 作为文本的开始和结束符号。\n捕捉和替换 从这里开始，正则表达式真正体现出了它的强大。\n捕获组 你已经知道了使用括号可以匹配一组符号。使用括号也可以捕获子串。假设正则表达式是一个小型计算机程序，那么捕获子串就是它输出的一部分。\n正则表达式 (\\w*)ility 表示匹配以 ility 结尾的词。第一个被捕获的部分是由 \\w* 控制的。比如，输入的文本内容中有单词 accessibility，那么首先被捕获的部分是 accessib。如果输入的文本中有单独的 ility，则首先被捕获的是一个空字符串。\n你可能会有很多的捕获字符串，它们可能靠得很近。捕获组从左向右编号。也就是只需要对左括号计数。\n假设有这样的正则表达式：(\\w+) had a ((\\w+) \\w+)\n输入的内容是：I had a nice day\n捕获组 1：I 捕获组 2：nice day 捕获组 3:nice 在一些正则表达式的实现中，你可以从零开始编号，编号零表示匹配整句话：I had a nice day. 在其他的实现中，如果没有制定捕获组，那么捕获组 1 会自动地填入捕获组 0 的信息。\n是的，这也意味着会有很多的括号。有一些正则表达式的实现中，提供了\u0026quot;非捕获组\u0026quot;的语法，但是这样的语法并不是标准语法，因此我们不会介绍。\n从一个成功的匹配中返回的捕获组个数，与使用原来的正则表达式获得的捕获组个数相同。记住这一点，你可以解释一些奇怪的现象。.\n正则表达式 ((cat）|dog) 表示匹配 cat 或者 dog。这里有两个捕获组，如果输入文本是 dog，那么捕获组 1 是 dog,捕获组 2 为空。\n正则表达式 a(\\w)\\* 表示匹配一个以 a 开头的单词。这里只有一个捕获组\n如果输入文本为 a ,捕获组 1 为空。 如果输入文本为 ad,捕获组为 d 如果输入文本为 avocado，捕获组 1 为 v。但是捕获组 0 表示整个单词 avocado. 替换 假如你使用了一个正则表达式去匹配字符串，你可以描述另外一个字符串来替换其中的匹配字符。用来替换的字符串称为替换表达式。它的功能类似于\n常规的 Replace 会话 Java 中的 String.replace() 函数 PHP 的 str_replace() 函数 等等 反向引用 在一个正则表达式中，你也可以引用捕获组。这称作：反向引用\n比如，[abc]{2} 表示匹配 aa 或者 ab 或者 ac 或者 ba 或者 bb 或者 bc 或者 ca 或者 cb 或者 cc。但是 {[abc]}\\1 表示只匹配 aa 或者 bb 或者 cc。\n使用正则表达式编程 特别提醒：\n过度使用的反斜杠 在一些编程语言，比如 Java 中，对于包含正则表达式的字符串没有特殊标记。字符串有着自己的过滤规则，这是优先于正则表达式规则的，这是频繁使用反斜杠的原因。\n比如在 Java 中\n匹配一个数字，使用的正则表达式从 \\d 变为代码中的 String re= \u0026quot;\\\\d\u0026quot;\n在其他的编程语言中，正则表达式是由特殊标明的，比如使用 /。下面是 JavaScript 的例子：\n匹配一个数字，\\d 会简单写成 var regExp = /\\d/; 匹配一个反斜杠或者一个左边的方括号或者一个右边的方括号， var regExp = /[\\\\\\[\\]]/; var regExp = /\\s/; 和 var regExp = /[ \\t\\r\\n]/; 是等价的 当然，这意味着在使用 / 时必须重复两次。比如找到 URL 必须使用 var regExp = /https?:\\/\\//;. 我希望现在你能明白，我为什么让你特别注意反斜杠。\n动态正则表达式 当你动态创建一个正则表达式的时候请特别小心。如果你使用的字符串不够完善的话，可能会有意想不到的匹配结果。这可能导致语法错误，更糟糕的是，你的正则表达式语法正确，但是结果无法预料。\n错误的 Java 代码：\nString sep = System.getProperty(\u0026#34;file.separator\u0026#34;); String[] directories = filePath.split(sep); Bug: String.split() 认为 sep 是一个正则表达式。但是，在 Windows 中，Sep 是表示匹配一个反斜杠，也就是与正则表达式\u0026quot;\\\u0026ldquo;相同。这个正则表达式是正确的，但是会返回一个异常：PatternSyntaxException。\n任何好的编程语言都会提供一种良好的机制来跳过字符串中所有的元字符。在 Java 中，你可以这样实现：\nString sep = System.getProperty(\u0026#34;file.separator\u0026#34;); String[] directories = filePath.split(Pattern.quote(sep)); 循环中的正则表达式 将正则表达式字符串加入反复运行的程序中，是一种开销很大的操作。如果你可以在循环中避免使用正则表达式，你可以大大提高效率。\n总结 字符: a b c d 1 2 3 4 etc. 字符类: . [abc] [a-z] \\d \\w \\s . 代表任何字符 \\d 表示\u0026quot;数字\u0026rdquo; \\w 表示\u0026quot;字母\u0026quot;, [0-9A-Za-z_] \\s 表示 \u0026ldquo;空格, 制表符,回车或换行符\u0026rdquo; 否定字符类: [^abc] \\D \\W \\S 重复: {4} {3,16} {1,} ? * + ? 表示 \u0026ldquo;零次或一次\u0026rdquo; * 表示 \u0026ldquo;大于零次\u0026rdquo; + 表示 \u0026ldquo;一次或一次以上\u0026rdquo; 如果不加上 ?，所有的重复都是最长匹配的（贪婪） 分组: (Septem|Octo|Novem|Decem)ber 词，行以及文本的分隔: \\b ^ $ \\A \\z 转义字符: \\1 \\2 \\3 etc. (在匹配表达式和替换表达式中都可用) 元字符: . \\ [ ] { } ? * + | ( ) ^ $ 在字符类中使用元字符: [ ] \\ - ^ 使用反斜杠可以忽略元字符: \\ 参考链接：\n30 分钟学习正则表达式 - Github ","permalink":"http://localhost:1313/regex-instruction/","summary":"\u003cp\u003e本文主要介绍了正则表达式的一些基本用法。\u003c/p\u003e","title":"正则表达式教程"},{"content":"本文主要介绍了如何解决 Windows 和 Linux 双系统时间不一致的问题。\n背景 当我们安装了 Windows 和 Linux 双系统后，经常会遇到两个系统时间不一致的问题，具体就是 Linux 系统的时间比 Windows 系统快了 8 个小时。这个问题是由于 Windows 和 Linux 系统处理系统硬件时间策略的不同带来的。\n首先介绍一个概念: 协调世界时（英语：Coordinated Universal Time，简称 UTC）是最主要的世界时间标准，其以原子时秒长为基础，在时刻上尽量接近于格林威治标准时间，即 0 时区。\nWindows 系统将计算机硬件时间当作本地时间(local time)，所以在 Windows 系统中显示的时间跟 BIOS 中显示的时间是一样的。\n而 Linux/Mac 将计算机硬件时间当作 UTC， 所以在 Linux/Mac 系统启动后在该时间的基础上，加上电脑设置的时区数（ 比如我们在中国，它就加上“8” ），因此，Linux/Mac 系统中显示的时间总是比 Windows 系统中显示的时间快 8 个小时。\n解决方案 由上可知，解决这个问题有两个方案，下面分别介绍。\n1. 让 Linux 使用本地时间 现代 Linux 一般都采用 systemd 来管理系统，这时可以通过 timedatectl 命令来更改\ntimedatectl set-local-rtc 1 --adjust-system-clock 执行后重启系统就可以了。\n2. 让 Windows 使用 UTC 时间 使用管理员权限打开命令行程序，输入以下命令来修改注册表。\nReg add HKLM\\SYSTEM\\CurrentControlSet\\Control\\TimeZoneInformation /v RealTimeIsUniversal /t REG_DWORD /d 1 参考链接：\n怎样解决 Windows10 时间快和 Ubuntu 时间差问题？ - 滑稽的回答- 知乎 ","permalink":"http://localhost:1313/dual-system-time-difference/","summary":"\u003cp\u003e本文主要介绍了如何解决 Windows 和 Linux 双系统时间不一致的问题。\u003c/p\u003e","title":"Windows 和 Linux 双系统时间不一致的问题"},{"content":"本文主要介绍了如何实现 Spring Boot 项目的全局异常捕获并处理。\n背景 异常处理是我们的 Web 项目中必不可少的一环。当发生了业务异常，如用户名不存在或是密码错误时，后端就需要将错误码和异常信息提供给前端，再要求用户实施进一步的操作。\n一种基本的方法就是在 Controller 层的每个接口中进行 try-catch，当捕获到异常时就根据异常类别返回对应的信息。不过这样会使得代码非常冗长，也不利于代码的维护。那么有没有什么比较优雅的处理办法呢？答案是肯定的，那就是 Spring Boot 的 ControllerAdvice 机制，下面进行介绍（注意，为方便起见，本文的项目引入了 Lombok）。\n异常定义 异常处理的第一步首先是要定义异常。\n基础异常接口类 首先定义一个基础的异常接口 BaseErrorInterface。里面包含两个方法，分别是获得错误码和获得异常信息。\npublic interface BaseErrorInterface { String getCode(); String getMsg(); } 错误码枚举类 然后定义自己的错误码枚举类 ErrorCode。定义项目中可能存在的异常，并实现上述接口的方法。\n@AllArgsConstructor public enum ErrorCode implements BaseErrorInterface { USER_NOT_FOUND(\u0026#34;4001\u0026#34;, \u0026#34;用户名不存在\u0026#34;), USER_ALREADY_EXIST(\u0026#34;4002\u0026#34;, \u0026#34;用户名已存在\u0026#34;), PASSWORD_WRONG(\u0026#34;4003\u0026#34;, \u0026#34;密码错误\u0026#34;), UNKNOWN_WRONG(\u0026#34;9999\u0026#34;, \u0026#34;发生了未知错误\u0026#34;); private final String code; private final String msg; @Override public String getCode() { return code; } @Override public String getMsg() { return msg; } } 自定义异常实现类 最后是创建一个类 ErrorException，完成异常定义并实现上述的基础异常接口。\npublic class ErrorException extends RuntimeException implements BaseErrorInterface { private BaseErrorInterface errorCode; public ErrorException() { super(); } public ErrorException(ErrorCode errorCode) { super(errorCode.getCode()); this.errorCode = errorCode; } public ErrorException(ErrorCode errorCode, Throwable throwable) { super(errorCode.getCode(), throwable); this.errorCode = errorCode; } @Override public String getCode() { return errorCode.getCode(); } @Override public String getMsg() { return errorCode.getMsg(); } } 这样异常定义的工作就完成了。\n全局异常捕获处理 HTTP 响应封装 定义类 Response，包含code，msg，data三个字段。code 为错误码，msg 为异常信息，而 data 为正常返回内容。\n@NoArgsConstructor @AllArgsConstructor @Getter @Builder @JsonInclude(JsonInclude.Include.NON_NULL) public class Response { private String code; private String msg; private Object data; public static Response success(Object data) { return Response.builder().data(data).build(); } public static Response failure(BaseErrorInterface e) { return Response.builder().code(e.getCode()).msg(e.getMsg()).build(); } } ControllerAdvice 最后就是创建全局异常捕获类了。在 Controller 层创建 ExceptionHandlerController，这样当调用 API 发生异常时它就可以捕获并统一处理了。\n@ControllerAdvice public class ExceptionHandlerController { @ExceptionHandler(value = ErrorException.class) public ResponseEntity\u0026lt;Response\u0026gt; handleErrorException(ErrorException e) { Response response = Response.failure(e); return ResponseEntity.ok(response); } @ExceptionHandler(value = Exception.class) public ResponseEntity\u0026lt;Response\u0026gt; handleOtherException() { BaseErrorInterface errorCode = ErrorCode.UNKNOWN_WRONG; Response response = Response.failure(errorCode); return ResponseEntity.ok(response); } } 这样全局捕获异常的功能就实现了。\n","permalink":"http://localhost:1313/spring-exception-handle/","summary":"\u003cp\u003e本文主要介绍了如何实现 Spring Boot 项目的全局异常捕获并处理。\u003c/p\u003e","title":"Spring Boot 全局异常捕获处理"},{"content":"本文主要介绍了如何让 Hugo 的 PaperMod 主题的语言设置为中文。\n配置文件修改语言 首先肯定是修改 config.yml 文件\nlanguageCode: zh defaultContentLanguage: zh menu: main: - name: 归档 url: archives weight: 10 - name: 分类 url: categories/ weight: 20 - name: 标签 url: tags/ weight: 30 - name: 搜索 url: search/ weight: 40 这样大部分内容就显示成中文了，不过一些页面还是英文，这就需要我们进一步的修改。\n归档和搜索页面 实现归档和搜索页面是我们在 content 目录下添加的 markdown 文件，要改为中文只需将其的 title 设为中文即可。\narchives.md\n--- title: \u0026#34;归档\u0026#34; layout: \u0026#34;archives\u0026#34; url: \u0026#34;/archives\u0026#34; summary: \u0026#34;archives\u0026#34; --- search.md\n--- title: \u0026#34;搜索\u0026#34; layout: \u0026#34;search\u0026#34; summary: \u0026#34;search\u0026#34; --- 标签分类和文章页面 要将标签和分类等页面改为中文需要在对应文件夹下添加 _index.md 文件。\ncontent\\categories\\_index.md\n--- title: \u0026#34;分类\u0026#34; --- content\\tags\\_index.md\n--- title: \u0026#34;标签\u0026#34; --- content\\posts\\_index.md\n--- title: \u0026#34;文章\u0026#34; --- 这样修改语言的工作就完成了。\n","permalink":"http://localhost:1313/papermod-lang-zh/","summary":"\u003cp\u003e本文主要介绍了如何让 Hugo 的 PaperMod 主题的语言设置为中文。\u003c/p\u003e","title":"PaperMod 主题语言设置中文"},{"content":"本文介绍了如何解决 Windows 系统开启 Hyper-V 之后端口被莫名占用的问题。\n在 Windows 操作系统中，当我们启用了 Hyper-V 或是 WSL 2（实际上 WSL 2 就是创建了一个 Hyper-V 虚拟机）之后，常常会遇到一些端口被占用的情况，而当我们使用 netstat 命令查找时，却又找不到是被什么程序占用了。\nnetstat -aon|findstr \u0026#34;port\u0026#34; 实际上，这些端口并不是被占用，而是被 Hyper-V 保留了。使用以下命令就可以查看 TCP 端口的保留范围。\nnetsh interface ipv4 show excludedportrange protocol=tcp 我们可以看到，Hyper-V 保留了很多低位端口。那么解决方案也就很简单了，只需将保留端口设置为不常用的高位端口就可以了。\nnetsh int ipv4 set dynamicport tcp start=50000 num=1000 netsh int ipv4 set dynamicport udp start=50000 num=1000 netsh int ipv6 set dynamicport tcp start=50000 num=1000 netsh int ipv6 set dynamicport udp start=50000 num=1000 重启之后，我们可以使用以下命令查看保留端口范围\nnetsh int ipv4 show dynamicport tcp 协议 tcp 动态端口范围 --------------------------------- 启动端口 : 50000 端口数 : 1000 这时，Hyper-V 占用的就都是 50000 以上的高位端口了。\n参考链接：\nThe default dynamic port range for TCP/IP has changed ","permalink":"http://localhost:1313/hyper-v-reserved-port/","summary":"\u003cp\u003e本文介绍了如何解决 Windows 系统开启 Hyper-V 之后端口被莫名占用的问题。\u003c/p\u003e","title":"解决 Hyper-V 端口占用问题"},{"content":"本文主要介绍了在 Win11 系统上启用 WSL 2，完成基本配置并安装 Docker 的过程。\n背景 Windows 11 系统对 WSL 2 进行了一系列的优化，尤其是解决了内存回收问题，这样当 Linux 子系统释放内存时主机就会将内存收回，不会再像 win10 一样一直占用很大的内存了。Windows 不愧是最佳 Linux 发行版 :D。在此之前，我一直通过 VMware 创建 Ubuntu 的虚拟机的方式来使用 Docker，现在利用 WSL 2，Linux 与主机的关联更加密切，开发起来就更方便了。\n安装 WSL 在 Win11 上安装 WSL 2 的方法非常简单，只需打开管理员权限的 powershell，输入以下命令\nwsl --install 并重启计算机，就会启用所需的可选组件，下载最新的 Linux 内核，将 WSL 2 设置为默认值，并安装 Linux 发行版（默认为 Ubuntu）。\n首次打开 WSL 时，需要我们设置用户名和密码。\nAPT 换源 Ubuntu 默认使用的是 HTTP 源，如果直接换 HTTPS 源的话会报证书错误，我们需要先执行\nsudo apt-get update sudo apt-get install \\ ca-certificates \\ curl \\ gnupg \\ lsb-release 然后再更换为国内的 HTTPS 源（如 USTC 源）。\n设置代理 WSL 2 设置代理一直是一个比较麻烦的问题。当我们使用 VMware 的虚拟机时，只需要开启 Windows 上 Clash for Windows（简称 CFW） 的允许局域网连接，并设置为 VMware 虚拟网卡的局域网中主机的 ip 地址和端口的代理就可以了。\n而 WSL 2 的 ip 地址每次开机都会变动，这样如果每次开机都去修改代理的 ip 就太麻烦了。当然一种办法是通过环境变量来动态获得 ip 地址，如\nexport host_ip=$(cat /etc/resolv.conf |grep -oP \u0026#39;(?\u0026lt;=nameserver\\ ).*\u0026#39;) export https_proxy=\u0026#34;http://${host_ip}:7890\u0026#34; export http_proxy=\u0026#34;http://${host_ip}:7890\u0026#34; export all_proxy=\u0026#34;http://${host_ip}:7890\u0026#34; 不过在一些不能通过环境变量来设置代理的软件中还是不太方便。\n一种比较好的方案是利用 CFW 的 TUN 模式。\n启动 TUN 模式需要进行如下操作：\n首先点击 General 中 Service Mode 右边 Manage，在打开窗口中安装服务模式，安装完成应用会自动重启，Service Mode 右边地球图标变为绿色即安装成功。\n然后进入 Settings 页面，滚动至 Profile Mixin 栏，点击 YAML 右边 Edit 小字打开编辑界面，在修改编辑界面内容为：\nmixin: # object dns: enable: true enhanced-mode: fake-ip nameserver: - 223.5.5.5 # 真实请求DNS，可多设置几个 - 119.29.29.29 - 114.114.114.114 # interface-name: WLAN # 出口网卡名称，或者使用下方的自动检测 tun: enable: true stack: gvisor # 使用 system 需要 Clash Premium 2021.05.08 及更高版本 dns-hijack: - 198.18.0.2:53 # 请勿更改 auto-route: true auto-detect-interface: true # 自动检测出口网卡 打开 Mixin，重启 CFW，这样 CFW 就会自动将 TUN 的配置内容添加到当前所用的配置文件中，这时所有流量都会由 CFW 接管了。\n安装 Docker 由于 WSL 2 没有 Systemd，所以如果我们在 WSL 里面安装 Docker 需要每次开机手动开启服务。所以推荐的方案是在 Windows 上安装 Docker Desktop 并启用 WSL 2 的后端。\n下载并安装 Docker Desktop 后，我们就可以使用 Docker 了。以安装 MySQL 的 docker 为例。\ndocker pull mysql docker run -d --name mysql-test -p 3306:3306 -e MYSQL_ROOT_PASSWORD=1234 mysql 这样就开启了一个 mysql 的服务。\n我们可以通过\ndocker exec -it mysql-test /bin/ 来进入容器。\n参考链接：\nInstall WSL TUN 模式 ","permalink":"http://localhost:1313/wsl2-docker-instruction/","summary":"\u003cp\u003e本文主要介绍了在 Win11 系统上启用 WSL 2，完成基本配置并安装 Docker 的过程。\u003c/p\u003e","title":"Windows 11 系统启用 WSL 2 并安装 Docker"},{"content":"本文主要介绍了 Git 的一些进阶操作，包括分离 HEAD，相对引用，cherry-pick，交互式 rebase 和 tag 等。\n分离 HEAD HEAD 是一个对当前检出记录的符号引用，也就是指向你正在其基础上进行工作的提交记录。HEAD 总是指向当前分支上最近一次提交记录。大多数修改提交树的 git 命令都是从改变 HEAD 的指向开始的。HEAD 通常情况下是指向分支名的（如 bugFix）。\n我们可以通过 checkout 一个分支\ngit checkout bugFix 来使 HEAD 指向该分支，\n也可以通过 chekcout 一个提交\ngit checkout C1 来使 HEAD 指向该提交。\n相对引用 通过指定提交记录哈希值的方式在 Git 中移动不太方便，所以 Git 引入了相对引用。使用相对引用的话，就可以从一个易于记忆的地方开始计算。相对引用有两个常用的用法：\n使用 ^ 向上移动 1 个提交记录 使用 ~\u0026lt;num\u0026gt; 向上移动 num 个提交记录 如：\ngit checkout HEAD^ 会向上移动 1 个提交记录。\n我们可以通过相对引用来移动分支。使用 -f 选项来让分支指向另一个提交。例如：\ngit branch -f main HEAD~3 会将 main 分支强制指向 HEAD 的第 3 级父提交。\n撤销变更 在 Git 中主要有两个方法来撤销变更，分别是 git reset 和 git revert。\ngit reset 通过把分支记录回退几个提交记录来实现撤销改动。你可以将这想象成“改写历史”。git reset 向上移动分支，原来指向的提交记录就跟从来没有提交过一样。实际上，在 reset 后，该提交所做的变更还在，但是处于未加入暂存区状态。如果我们要删除所做的更改，可以使用 --hard 选项。\n虽然在你的本地分支中使用 git reset 很方便，但是这种“改写历史”的方法对大家一起使用的远程分支是无效的哦！为了撤销更改并分享给别人，我们需要使用 git revert。\ngit revert 会在要撤销的提交后面新增一个提交，新提交的更改正是为了撤销上一个提交。因此 revert 之后我们就可以将更改推送到远程仓库与别人分享了。\nCherry-pick git cherry-pick 是整理提交记录的第一种方法。\ncherry-pick 可以将一些提交复制到当前所在的位置（HEAD）下面，如 side 分支上有 C2，C3，C4 三个提交，而我们只想将其中两个复制到 main 分支，就可以\ngit cherry-pick C2 C4 交互式 rebase 当你知道你所需要的提交记录（并且还知道这些提交记录的哈希值）时, 用 cherry-pick 再好不过了。但是如果你不清楚你想要的提交记录的哈希值呢? 那么这时我们可以利用交互式的 rebase——如果你想从一系列的提交记录中找到想要的记录, 这就是最好的方法了。\n交互式 rebase 指的是使用带参数 --interactive 的 rebase 命令, 简写为 -i。如果你在命令后增加了这个选项, Git 会打开一个 UI 界面并列出将要被复制到目标分支的备选提交记录，它还会显示每个提交记录的哈希值和提交说明，提交说明有助于你理解这个提交进行了哪些更改。\n交互式 rebase 的界面如下例所示：\npick f7f3f6d Change my name a bit pick 310154e Update README formatting and add blame pick a5f4a0d Add cat-file # Rebase 710f0f8..a5f4a0d onto 710f0f8 # # Commands: # p, pick \u0026lt;commit\u0026gt; = use commit # r, reword \u0026lt;commit\u0026gt; = use commit, but edit the commit message # e, edit \u0026lt;commit\u0026gt; = use commit, but stop for amending # s, squash \u0026lt;commit\u0026gt; = use commit, but meld into previous commit # f, fixup \u0026lt;commit\u0026gt; = like \u0026#34;squash\u0026#34;, but discard this commit\u0026#39;s log message # x, exec \u0026lt;command\u0026gt; = run command (the rest of the line) using # b, break = stop here (continue rebase later with \u0026#39;git rebase --continue\u0026#39;) # d, drop \u0026lt;commit\u0026gt; = remove commit # l, label \u0026lt;label\u0026gt; = label current HEAD with a name # t, reset \u0026lt;label\u0026gt; = reset HEAD to a label # m, merge [-C \u0026lt;commit\u0026gt; | -c \u0026lt;commit\u0026gt;] \u0026lt;label\u0026gt; [# \u0026lt;oneline\u0026gt;] # . create a merge commit using the original merge commit\u0026#39;s # . message (or the oneline, if no original merge commit was # . specified). Use -c \u0026lt;commit\u0026gt; to reword the commit message. # # These lines can be re-ordered; they are executed from top to bottom. # # If you remove a line here THAT COMMIT WILL BE LOST. # # However, if you remove everything, the rebase will be aborted. # # Note that empty commits are commented out 在交互式 rebase 的界面中，我们可以\n修改提交顺序。只需在编辑器中修改各行的顺序即可。 合并提交。我们可以将多个提交合并到一个提交中。方法是将想要的提交设置为 pick，而将想要合并的提交设置为 squash。保存后会出现一个新的编辑器窗口，在这里面可以修改提交信息。 拆分提交。我们也可以将一个提交拆分成多个提交。方法是将想要拆分的提交设置为 edit，保存退出后 git 会提示在该提交处停止了。这里可以用 git commit --amend 命令对提交信息重新编辑。而我们是要拆分提交，所以要先将提交 reset，然后重新提交。拆分完成后使用 git rebase --continue 结束 rebase。 删除提交。方法是在编辑器中直接删除那一行，保存退出后 git 会比较其前后两个提交的差异，如果有冲突需要手动解决冲突之后再 git rebase --continue。 Tag 我们知道，分支很容易被人为移动，并且当有新的提交时，它也会移动。分支很容易被改变，大部分分支还只是临时的，并且还一直在变。那么有没有什么可以永远指向某个提交记录的标识呢，比如软件发布新的大版本，或者是修正一些重要的 Bug 或是增加了某些新特性。 Git 的 Tag 正是这个用途。\n它们可以永久地将某个特定的提交命名为里程碑，然后就可以像分支一样引用了。更难得的是，它们并不会随着新的提交而移动。你也不能检出到某个标签上面进行修改提交，它就像是提交树上的一个锚点，标识了某个特定的位置。\ngit tag v1 C1 就将 C1 提交记录标记为了 1.0 版本。\nDescribe git describe的语法是\ngit describe \u0026lt;ref\u0026gt; \u0026lt;ref\u0026gt; 可以是任何能被 Git 识别成提交记录的引用，如果你没有指定的话， Git 会以你目前所检出的位置（HEAD）。\n它输出的结果是这样的：\n\u0026lt;tag\u0026gt;_\u0026lt;numCommits\u0026gt;_g\u0026lt;hash\u0026gt; tag 表示的是离 ref 最近的标签，numCommits 是表示这个 ref 与 tag 相差有多少个提交记录，hash 表示的是你所给定的 ref 所表示的提交记录哈希值的前几位。当 ref 提交记录上有某个标签时，则只输出标签名称。\n例如，对于下面的提交树\ngit describe main 会输出：\nv1_2_gC2 git describe side 会输出：\nv2_1_gC4 参考链接：\nlearngitbranching.js.org ","permalink":"http://localhost:1313/git-instruction-2/","summary":"\u003cp\u003e本文主要介绍了 Git 的一些进阶操作，包括分离 HEAD，相对引用，cherry-pick，交互式 rebase 和 tag 等。\u003c/p\u003e","title":"Git 使用教程（下）"},{"content":"本文主要介绍了 Git 本地和远程的一些常用操作，包括 commit，branch，merge，rebase，fetch 和 push 等。\n基本操作 Commit Git 仓库中的提交记录保存的是你的目录下所有文件的快照。 Git 希望提交记录尽可能地轻量，因此在你每次进行提交时，它并不会盲目地复制整个目录。条件允许的情况下，它会将当前版本与仓库中的上一个版本进行对比，并把所有的差异打包到一起作为一个提交记录。 Git 还保存了提交的历史记录。\n使用方法为\ngit commit -m \u0026#34;Some Message\u0026#34; Branch Git 的分支也非常轻量。它们只是简单地指向某个提交纪录，仅此而已。因此即使创建再多的分支也不会造成储存或内存上的开销，并且按逻辑分解工作到不同的分支要比维护那些特别臃肿的分支简单多了。所以使用 Git 的一个原则就是早建分支，多用分支。\n创建一个新的分支\ngit branch newBranch 切换到该分支\ngit checkout newBranch 上述两条命令可以由一种更简洁的方式实现\ngit checkout -b newBranch Merge 现在我们讨论如何将两个分支合并到一起。就是说我们新建一个分支，在其上开发某个新功能，开发完成后再合并回主线。完成该操作的第一种方法是 git merge。\n例如，我们要将 bugFix 分支合并到 main 分支里，切换到 main 分支，执行\ngit merge bugFix 这样 main 分支就包含了对代码库的所有修改。\nRebase 合并分支的第二种方法是 git rebase。Rebase 实际上就是取出一系列的提交记录，“复制”它们，然后在另外一个地方逐个的放下去。Rebase 的优势就是可以创造更线性的提交历史。\n我们想要把 bugFix 分支里的工作直接移到 main 分支上。移动以后会使得两个分支的功能看起来像是按顺序开发，但实际上它们是并行开发的。注意当前所在的分支是 bugFix。\ngit rebase main 事实上，git rebase 可以添加两个参数，后面的参数默认为当前的分支。\ngit rebase \u0026lt;baseBranch\u0026gt; \u0026lt;topicBranch\u0026gt; 会将 topicBranch 变基到 baseBranch 上，也就是将 topicBranch 的代码“续”到了 baseBranch 后面。\n上面的命令等价于\ngit rebase main bugFix 这样，我们在进行 rebase 时就不需要频繁切换分支了。\n我们只需要记住，rebase 时修改的是后面的分支，前面的分支不动就可以了。\nMerge 和 Rebase 的选择 那么，我们在合并分支时应该什么时候使用 rebase，什么时候使用 merge 呢？\n一个基本的原则是\nsub-branches rebase on master, master merges sub-branches.\n也就是在上例中，我们如果想要将 bugFix 里的工作合并到 main 中，应当采用\ngit rebase main git checkout main git merge bugFix 远程仓库 Clone 远程仓库并不复杂, 在如今的云计算盛行的世界很容易把远程仓库想象成一个富有魔力的东西, 但实际上它们只是你的仓库在另个一台计算机上的拷贝。你可以通过因特网与这台计算机通信 —— 也就是增加或是获取提交记录。话虽如此, 远程仓库却有一系列强大的特性：\n首先也是最重要的的点, 远程仓库是一个强大的备份。本地仓库也有恢复文件到指定版本的能力, 但所有的信息都是保存在本地的。有了远程仓库以后，即使丢失了本地所有数据, 你仍可以通过远程仓库拿回你丢失的数据。 还有就是, 远程让代码社交化了! 既然你的项目被托管到别的地方了, 你的朋友可以更容易地为你的项目做贡献(或者拉取最新的变更) git clone 命令的作用是在本地创建一个远程仓库的拷贝（比如从 github.com）。\n当我们 clone 一个具有子模块的项目时，默认会包含该子模块目录，但其中还没有任何文件。我们必须运行两个命令：git submodule init 用来初始化本地配置文件，而 git submodule update 则从该项目中抓取所有数据并检出父项目中列出的合适的提交。\n不过，还有一种更简单的方式，如果给 git clone 命令传递 --recurse-submodules 选项，它就会自动初始化并更新仓库中的每一个子模块， 包括可能存在的嵌套子模块。\nFetch \u0026amp; Pull git fetch 用于从远程仓库中获取数据。\ngit fetch 完成了仅有的但是很重要的两步:\n从远程仓库下载本地仓库中缺失的提交记录 更新远程分支指针(如 origin/main) git fetch 实际上将本地仓库中的远程分支更新成了远程仓库相应分支最新的状态。\n而 git fetch 并不会改变你本地仓库的状态。它不会更新你的 main 分支，也不会修改你磁盘上的文件。\n因此，我们需要执行通过以下命令来将这些变化更新到我们的工作当中。\ngit cherry-pick origin/main git rebase origin/main git merge origin/main 实际上，由于先抓取更新再合并到本地分支这个流程很常用，因此 Git 提供了一个专门的命令来完成这两个操作。它就是我们要讲的 git pull。git pull 相当于 git fetch 和 git merge 两个操作。\n例如\ngit fetch git merge origin/main 和\ngit pull 完全等价。\nPush git push 负责将你的变更上传到指定的远程仓库，并在远程仓库上合并你的新提交记录。一旦 git push 完成, 你的朋友们就可以从这个远程仓库下载你分享的成果了！\n但是，当历史偏离时 git push 会失败。比如你最新提交的 C3 基于远程分支中的 C1。而远程仓库中该分支已经更新到 C2 了，所以 Git 拒绝了你的推送请求。实际上它会强制你先合并远程最新的代码，然后才能分享你的工作。\n那该如何解决这个问题呢？很简单，你需要做的就是使你的工作基于最新的远程分支。有许多方法可以做到这一点，不过最直接的方法就是通过 rebase 调整你的工作。\n我们可以在 push 之前做 rebase\ngit fetch git rebase origin/main git push 当然，也可以使用 merge。尽管 git merge 不会移动你的工作（它会创建新的合并提交），但是它会告诉 Git 你已经合并了远程仓库的所有变更。这是因为远程分支现在是你本地分支的祖先，也就是说你的提交已经包含了远程分支的所有变化。\n实际上，我们使用\ngit pull --rebase git push 就可以更加方便地完成，这和上文的 rebase 方法完全相同。当然，如果使用 git pull，那么就相当于上文的 merge 方法了。\ngit rm \u0026ndash;cached 在上传文件到 Git 上时，有时候会将本地的一些配置文件传到服务器上，这时候如果先删除本地，再同步服务器显然是不合理的。这时 Git 给我们提供了一种解决方法，可以直接删除服务器文件而不影响本地。命令如下：\ngit rm --cached filename git rm --cached -r directory 当我们提交并推送之后，服务器上的文件就不存在了。\n参考链接：\nlearngitbranching.js.org ","permalink":"http://localhost:1313/git-instruction-1/","summary":"\u003cp\u003e本文主要介绍了 Git 本地和远程的一些常用操作，包括 commit，branch，merge，rebase，fetch 和 push 等。\u003c/p\u003e","title":"Git 使用教程（上）"},{"content":"本文主要介绍一些常用软件的设置网络代理或者更换软件镜像源的方式。本文包括以下软件的设置：shell, git, apt, conda, maven, gradle, npm, yarn 以及 docker。\n1. shell 为 shell（以 zsh 为例）设置代理需要编辑 ~/zshrc（ 用户为 ~/.rc）文件，添加如下内容\nexport http_proxy=http://127.0.0.1:7890/ export https_proxy=http://127.0.0.1:7890/ 然后执行\nsource .zshrc 此时运行在当前终端的应用程序就会应用此代理。\n2. git 为 git 设置代理需要执行\ngit config --global http.proxy http://127.0.0.1:7890/ git config --global https.proxy http://127.0.0.1:7890/ 需要注意的是，只有通过 HTTPS 方式进行 clone 或 push 等操作时才会应用此代理，而通过 SSH 方式时仍然为直连。\n3. apt 为 apt 设置代理需要编辑 /etc/apt/apt.conf.d/proxy.conf 文件\nAcquire::http::Proxy \u0026#34;http://127.0.0.1:7890/\u0026#34;; Acquire::https::Proxy \u0026#34;http://127.0.0.1:7890/\u0026#34;; 4. conda 为 conda 设置代理需要编辑 ~/.condarc 文件\nproxy_servers: http: http://127.0.0.1:7890/ https: http://127.0.0.1:7890/ 5. maven 为 maven 设置代理需要编辑 ~/.m2/settings.xml 文件，修改其中的 部分\n\u0026lt;proxies\u0026gt; \u0026lt;proxy\u0026gt; \u0026lt;id\u0026gt;http_proxy\u0026lt;/id\u0026gt; \u0026lt;active\u0026gt;true\u0026lt;/active\u0026gt; \u0026lt;protocol\u0026gt;http\u0026lt;/protocol\u0026gt; \u0026lt;host\u0026gt;127.0.0.1\u0026lt;/host\u0026gt; \u0026lt;port\u0026gt;7890\u0026lt;/port\u0026gt; \u0026lt;/proxy\u0026gt; \u0026lt;/proxies\u0026gt; 6. gradle 为 gralde 设置代理需要编辑 ~/.gradle/gradle.properties 文件\nsystemProp.http.proxyHost=127.0.0.1 systemProp.http.proxyPort=7890 systemProp.https.proxyHost=127.0.0.1 systemProp.https.proxyPort=7890 7. npm \u0026amp; yarn 由于前端开发时 node_modules 需要下载的小文件太多，使用代理的效果不好，所以 npm 不使用代理，而是设置国内的腾讯云镜像源。\nnpm 换源需要执行\nnpm config set registry https://mirrors.cloud.tencent.com/npm/ 而 yarn 换源需要执行\nyarn config set registry https://mirrors.cloud.tencent.com/npm/ 8. docker docker 同样推荐使用国内的阿里云镜像加速器。修改 /etc/docker/daemon.json 文件\n{ \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;your.mirror.address\u0026#34;] } 然后执行\nsudo systemctl daemon-reload sudo systemctl restart docker ","permalink":"http://localhost:1313/software-set-proxy-mirror/","summary":"\u003cp\u003e本文主要介绍一些常用软件的设置网络代理或者更换软件镜像源的方式。本文包括以下软件的设置：shell, git, apt, conda, maven, gradle, npm, yarn 以及 docker。\u003c/p\u003e","title":"常用软件设置代理及换源教程"},{"content":"本文主要介绍了如何在 Hugo 静态博客中优雅地插入图片。\n如何显示图片 由于 Hugo 生成的是静态博客，因此插入图片是一件相对比较麻烦的事情。当然，一个简单的方法就是采用图床，不过大部分图床都需要收费，免费的也不能保证稳定性，而我们的博客所用的图片数量也并不算多，所以我们可以采取随 markdown 源文件一起存储的方法。\nHugo 普遍的新建博文的方式是 hugo new posts/new-post.md，这样我们可以将图片都存放在 Blog/static/ 目录下，这样经过编译之后图片会存放到网站的根目录。不过如果这样，那么在编写博客的时候编辑器就没办法显示图片，只能凭感觉了。而放到其他目录时，编译后的网站又不能识别。\n一个较为优雅的方式就是\nhugo new posts/new-post/index.md 将新的博文创建成一个文件夹，将 markdown 源文件命名为 index.md，再在文件夹内创建 pics 文件夹，将图片放入该文件夹，在编写博文插入图片时使用相对路径，即 pics/1.png，这样在编辑器中就可以看到图片了。\n而当网站编译完成之后，文件夹的格式就会如下所示\nfirst-post pics 1.png index.html index.html 文件与 pics 文件夹同级，网站同样也可以识别 html 文件中的图片路径。\n改变图片大小和布局 解决了图片的存储位置之后，另一个问题就是如何改变图片的大小。\n当我们采用 markdown 默认的图片插入方式，即 ![pic](pic.png) 时，图片的宽度默认为编辑器的宽度，而且不能调节，这样当我们插入一些比较小的图片时也会占据很大的空间，非常影响文章的阅读体验。\n这时我想到的一个方法就是采用 HTML 标签的方法来插入图片，即\n\u0026lt;img src=\u0026#34;pic.png\u0026#34; width=\u0026#34;50%\u0026#34; align=\u0026#34;center\u0026#34; /\u0026gt; 这样在编辑器中倒是可以正常显示，不过编译完之后图片全部变成左对齐了，这说明 align 没有发挥作用。\n最终的解决方案是\n\u0026lt;center\u0026gt;\u0026lt;img src=\u0026#34;pic.png\u0026#34; width=\u0026#34;50%\u0026#34; /\u0026gt;\u0026lt;/center\u0026gt; 这样就可以实现图片居中显示了。\n显示图注 当文章的图片比较多的时候我们经常需要使用图注，当然我们可以直接这样\n\u0026lt;center\u0026gt;\u0026lt;img src=\u0026#34;pic.png\u0026#34; width=\u0026#34;50%\u0026#34; /\u0026gt;\u0026lt;/center\u0026gt; \u0026lt;center\u0026gt;图1\u0026lt;/center\u0026gt; 不过显示效果较差，不太优雅。那么有没有什么比较好的办法呢？\n答案是肯定的。Hugo 官方提供了一些 shortcodes 短代码，其中就包含插入图片的短代码 figure。上例可以用 figure 来较为优雅地解决。（去掉代码中的反斜杠）\n\u0026lt;center\u0026gt;\\{\\{\u0026lt; figure src=\u0026#34;pic.png\u0026#34; width=\u0026#34;50%\u0026#34; title=\u0026#34;图1\u0026#34; \u0026gt;}}\u0026lt;/center\u0026gt; ","permalink":"http://localhost:1313/hugo-blog-picture/","summary":"\u003cp\u003e本文主要介绍了如何在 Hugo 静态博客中优雅地插入图片。\u003c/p\u003e","title":"Hugo 博客插入图片的方法"},{"content":"本文主要介绍了如何利用 Hugo 和 Github Pages 创建静态博客，并利用 Github Actions 实现博客的自动部署。\n背景介绍 Hugo Hugo 是一个用 Go 编写的静态网站生成器，Hugo 一般只需几秒钟就能生成一个网站（每页少于 1 毫秒），被称为“世界上最快的网站构建框架”。这也使 Hugo 大受欢迎，成为最热门的静态网站生成器之一，被广泛采用。\n静态博客最常用的两个框架就是 Hugo 和 Hexo。由于 Hexo 是由 Node.js 编写，在文章数量较大之后就需要比较长的编译时间，因此由于性能考虑我们采用 Hugo 作为我们博客的框架。\nGithub Pages GitHub Pages 是 GitHub 提供的一个免费网页寄存服务，可以用于存放静态网页，包括博客、项目文档甚至整本书。利用 Github Pages 部署静态博客，就可以免去部署服务器的费用，减少成本。不过，静态博客由于没有数据库，因此在后台管理方面就不如动态博客（如 WordPress 等）方便。\nGithub Actions Github Actions 提供了免费的 CI/CD 功能，能够帮助我们自动完成软件开发周期内的任务。 GitHub Actions 是事件驱动的，意味着可以在指定事件发生后运行一系列命令。 例如，每次有人为仓库创建拉取请求时，都可以自动运行命令来执行软件测试脚本。\n利用 Github Actions，我们就可以实现博客的自动部署。每当我们对仓库完成 push 操作时，Github 就能自动进行编译并完成静态文件的部署。\n博客建立 我们首先下载 Hugo，推荐下载 extended 版本。解压并设置好环境变量后，打开终端，输入\nhugo new site Blog 这样就建立了一个新的博客。\n我们可以建立一篇新的文章。\nhugo new posts/first-post/index.md 这样，就会在 Blog/content/posts/first-post/下生成一个名为 index.md的文件。\n编写完博客之后，我们可以通过\nHugo server -D 来对网站进行实时预览，以及通过\nHugo 来将网站进行编译。\n选择主题 我推荐的主题是 PaperMod 主题。我们可以通过此命令来安装该主题\ngit submodule add https://github.com/adityatelange/hugo-PaperMod.git themes/PaperMod --depth=1 而当我们重新 clone 我们的仓库时，如果主题没有自动下载，需要运行以下命令\ngit submodule update --init --recursive # needed when you reclone your repo (submodules may not get cloned automatically) 具体的配置可以参照仓库的 Wiki，这里简单介绍以下如何添加归档和搜索页面。\n在 Blog/contend/ 下创建 archives.md 和 search.md，内容分别为：\narchives.md\n--- title: \u0026#34;Archive\u0026#34; layout: \u0026#34;archives\u0026#34; url: \u0026#34;/archives\u0026#34; summary: \u0026#34;archives\u0026#34; --- search.md\n--- title: \u0026#34;Search\u0026#34; layout: \u0026#34;search\u0026#34; summary: \u0026#34;search\u0026#34; --- 然后修改 config.yml 配置文件，将 menu 部分改为\nmenu: main: - name: Archives url: archives weight: 10 - name: Categories url: categories/ weight: 20 - name: Tags url: tags/ weight: 30 - name: Search url: search/ weight: 40 这样博客就有了归档和搜索页面。\n建立远程仓库 我们在 Github 上建立名为 username.github.io 的仓库，然后将本地的博客与远程仓库的 source 分支对应，添加 .gitignore 文件后就可以将文件都推送到该分支了。而 main 分支作为我们 Pages 展示的分支，暂时留空，它将在后面由 Github Actions 自动生成并部署。\n使用脚本简化操作 我们可以通过 脚本来简化博客的操作。\n首先是部署的脚本 deploy.sh\n#!/bin/ # 添加所有修改 git add . # 设置提交说明，格式为 Site updated: 2006-01-02 15:04:05 time=$(date \u0026#34;+%Y-%m-%d %H:%M:%S\u0026#34;) commit=\u0026#34;Site updated:\u0026#34;$time echo $commit # 提交 git commit -m \u0026#34;$commit\u0026#34; # 推送到source分支上 git push origin source 然后修改 .zshrc 文件，添加几个简写\n# Hugo export BLOG_HOME=\u0026#34;$HOME/Blog\u0026#34; alias hs=\u0026#34;cd $BLOG_HOME \u0026amp;\u0026amp; hugo server -D\u0026#34; alias hd=\u0026#34;cd $BLOG_HOME \u0026amp;\u0026amp; sh deploy.sh\u0026#34; alias hb=\u0026#34;cd $BLOG_HOME \u0026amp;\u0026amp; rm -rf public/* \u0026amp;\u0026amp; hugo\u0026#34; hn() { cd $BLOG_HOME \u0026amp;\u0026amp; hugo new posts/$1/index.md } 这样，我们就可以通过 hs 实现预览，通过 hb 实现博客编译，通过 hd 实现博客部署，通过 hn new-post 创建新的博文了。\nGithub Actions 自动部署 首先，我们要先在 Github 上申请一个 personal access token。选择 Token 的作用域时可以根据需要选择，也可以直接全选。完成后 Github 会提供一个 Token，注意该 Token 只会出现一次，我们需要保存好，如果忘记就只能重新申请了。\n插一句题外话，实际上，由于 Github 现在已经不再支持密码验证，当我们进行 push 操作时同样也需要 Token。为了简便，我们可以将仓库的远程地址换成 https://\u0026lt;token\u0026gt;@github.com/user/repo.git，这样在 push 时就不需要要求验证了。\n然后在远程仓库的 Settings/Secrets 中添加你的 Personal access token。\n最后在本地仓库中新建 Blog/.github/workflows/gh-pages.yml 文件\nname: github pages on: push: branches: - source # Set a branch to deploy jobs: deploy: runs-on: ubuntu-20.04 steps: - uses: actions/checkout@v2 with: submodules: recursive # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#34;latest\u0026#34; extended: true - name: Build run: hugo --minify - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: github_token: ${{ secrets.ACTIONS_TOKEN }} publish_dir: ./public publish_branch: main cname: your_domain 注意需要将 github_token 的名称改为你仓库中 token 的名字，并将 cname 换成你自己的域名，如不需要更换也可以删除。更换后也需要到域名的 DNS 管理处添加 CNAME 到 username.github.io。\n并且，Github 还会自动为我们申请 SSL 证书，我们可以到仓库的 Github Pages 设置页面打开 HTTPS 访问。\n这样，每当我们将源码推送到 source 分支后，Github 就会自动就编译后的静态文件部署到 main 分支并发布到 Github Pages 中了。\n从远程仓库下载 当我们更换了一台新的电脑或是本地仓库被损坏时，可以从远程仓库中下载博客。为了下载博客的主题，需要添加 --recurse-submodules 参数。\ngit clone username.github.io --recurse-submodules ","permalink":"http://localhost:1313/hugo-github-pages-blog/","summary":"\u003cp\u003e本文主要介绍了如何利用 Hugo 和 Github Pages 创建静态博客，并利用 Github Actions 实现博客的自动部署。\u003c/p\u003e","title":"利用 Hugo 和 Github Pages 创建静态博客并实现自动部署"},{"content":"Virtual Puppet Project, often shortened to vpuppr, aims to be an accessible, open-source tool for VTubers!\nFound a problem with the program? Submit an issue on GitHub!\nFeel free to join the Discord community to share your thoughts or help collaborate!\nContributors Check out the people who helped build this!\nvpuppr\nwebsite\nDemo Here\u0026rsquo;s a quick demo from a slightly older alpha version by ItsRogueRen.\n","permalink":"http://localhost:1313/about/","summary":"Virtual Puppet Project, often shortened to vpuppr, aims to be an accessible, open-source tool for VTubers!\nFound a problem with the program? Submit an issue on GitHub!\nFeel free to join the Discord community to share your thoughts or help collaborate!\nContributors Check out the people who helped build this!\nvpuppr\nwebsite\nDemo Here\u0026rsquo;s a quick demo from a slightly older alpha version by ItsRogueRen.","title":""},{"content":"Project Links In no particular order, here are some links to my various open source projects.\ncamply browsr cookiecutter-python llm-term dotfiles hatch-pip-compile dotfiles lunchable lunchable-pushlunch lunchable-primelunch lunchable-splitlunch media-center textual-universal-directorytree zoo ridbPy recdotgov-client FastApp ","permalink":"http://localhost:1313/links/","summary":"Project Links In no particular order, here are some links to my various open source projects.\ncamply browsr cookiecutter-python llm-term dotfiles hatch-pip-compile dotfiles lunchable lunchable-pushlunch lunchable-primelunch lunchable-splitlunch media-center textual-universal-directorytree zoo ridbPy recdotgov-client FastApp ","title":""},{"content":"\u003c!doctype html\u003e Justin Flannery - Resume ","permalink":"http://localhost:1313/resume/","summary":"\u003c!doctype html\u003e Justin Flannery - Resume ","title":""}]